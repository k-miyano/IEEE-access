\documentclass{ieeeaccess}

\usepackage[dvipdfmx]{graphicx}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{comment}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{amsmath,amssymb,,amsfonts}
\usepackage{ascmac}
\usepackage{bm}
\usepackage{cite}
\usepackage{nidanfloat}
\usepackage{url}
\usepackage{color}
\usepackage{algorithmic}
\usepackage{textcomp}

\usepackage[utf8]{inputenc}
\usepackage[whole]{bxcjkjatype}
\usepackage{xcolor}

\def\rnum#1{\expandafter{\romannumeral #1}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newcommand{\argmin}{\mathop{\rm arg~min}\limits}
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}


\begin{document}
\history{Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.}
\doi{10.1109/ACCESS.2017.DOI}
\title{Utility Based Scheduling for Multi-UAV Search Systems in Disaster-hit Areas}

\author{\uppercase{Kosei MIYANO\authorrefmark{1}, Ryoichi SHINKUMA\authorrefmark{1}, NARAYAN B. MANDAYAM\authorrefmark{2}, Takehiro SATO\authorrefmark{1}, and Eiji OKI\authorrefmark{1}}}
\address[1]{Graduate School of Informatics, Kyoto University Yoshida-honmachi, Sakyo-ku, Kyoto 606-8501, Japan}
\address[2]{Wireless Information Network Laboratory (WINLAB), Rutgers University, 671 Route 1 South, North Brunswick, NJ, 08902-3390, USA}
\tfootnote{This work was partly supported by JSPS KAKENHI Grant Number JP17H01732.}

\markboth
{K. Miyano \headeretal: Utility Based Scheduling for Multi-UAV Search Systems in Disaster-hit Areas}
{K. Miyano \headeretal: Utility Based Scheduling for Multi-UAV Search Systems in Disaster-hit Areas}

\corresp{Corresponding author: K. Miyano (e-mail: kmiyano@icn.cce.i.kyoto-u.ac.jp).}

\begin{IEEEkeywords}
unmanned aerial vehicle, target search, scheduling, edge computing
\end{IEEEkeywords}

\begin{abstract}
Micro or small unmanned aerial vehicles (UAVs) is a promising solution for finding people who have disappeared because of getting lost in unexpected situation like disaster.
It takes long time to analyze the acquired image data for the target recognition due to the limited computational resource of small UAVs.
In addition, the data transfer time can increase in the disaster-hit areas due to the  damage of communication infrastructures.
However, the prior researches did not consider both processing time of the acquired data and data transfer time, though, from a user-centric viewpoint, the temporal requirement in such surveillance scenarios is strict.

Therefore, this paper proposes a scheduling method of multi-UAV search system that considers processing time of image data and data transfer time.
We present the utility-based problem formulation that ensures the freshness of individual obtained piece of information while obtaining as many pieces of information as possible for a certain period.
Simulation results verify that the proposed scheduling method maximizes the user's utility and works better than the benchmarks in terms of user-centric evaluation metrics.
\end{abstract}

\maketitle
\IEEEpeerreviewmaketitle

\section{introduction}\label{intro}
The number of deaths and missing people due to natural disasters is still a serious problem in many countries.
According to a report by Centre for Research on the Epidemiology of Disasters\cite{CRED2016}, the average number of deaths and missing people due to natural disasters occurring all over the world, such as earthquakes, hurricanes, forest fires, and floods, from 2006 to 2015 was approximately 70,000.
In order to reduce the number, one of the solutions to reduce the number is to increase the number of rescue teams.
The report by Japan Ministry of Defense after the great east Japan earthquake suggests that  it is necessary to secure manpower through guidelines for the concentration of units in the immediate aftermath of a disaster.
%
However, a huge budget is required to secure manpower and the risk of secondary damages in disaster occurrence areas is serious remaining issues to be solved\cite{disaster2011}.
%
Micro or small unmanned aerial vehicles (UAVs), also known as drones, are expected to be emerging solutions to solve the above problem in areas where humans and ground vehicles cannot easily step into like disaster-damaged areas.
Technological advances in the recent years have led to the emergence of smaller and cheaper UAVs, which can provide some functions such as transporting relief supplies, collecting data by using onboard sensors, and forming adhoc wireless mesh network infrastructure in such isolated areas \cite{Andre2014,Erdelj2016,Felice2014}.
Collecting image data is especially important because it is applicable to many use cases such as search, and rescue mission, fire detection and surveillance.
%
Since there are time constraints in such situations, UAVs need to collect sensor data as soon as possible.
In the great east Japan earthquake, as time passed, the number of deaths and missing people  dramatically increased\cite{japan2011}.
Surveillance using multiple UAVs has been receiving increasing attention for reasons such as increase in system reliability, robustness, and efficiency\cite{Lanillos2014,Maza2007,Meng2014,chang2016,Mirzaei2011}.

However, although from a user-centric viewpoint, the time requirement in such surveillance scenarios should be strict, the prior works assumed that the user can obtain necessary information as soon as UAV acquires image data: both processing time of image data and data transfer time are not taken into consideration. In the practical situation, it takes long time to analyze images for target recognition due to the limited computational resource of small UAVs. In addition, the data transfer time can increase in the disaster-hit areas due to the damage of communication infrastructures.

Therefore, this paper proposes a scheduling method of multi-UAV search system that considers processing time of image data and data transfer time.
We present the utility-based problem formulation that ensures the freshness of individual obtained piece of information while obtaining as many pieces of information as possible for a certain period.
We show that the proposed scheduling method maximizes the user's utility, which is calculated from the efficiency of obtaining results from analyzed data and the interval of obtaining the results, through the basic performance evaluation.
We also conduct the simulation using the three evaluation metric from a user-centric viewpoint to verify the effectiveness of the the proposed scheduling method against the benchmarks.

The remainder of this paper is organized as follows. Section II discusses the related work. Section III presents the system overview and proposed scheduling method. Section IV then provides the basic performance evaluation in terms of the user's utility, followed by the simulation using the three evaluation metric from a user-centric viewpoint in Section V. Finally, Section VI concludes this paper. Note this paper is an extended version of the one the authors presented at IEEE GCCE 2018 \cite{GCCE2018}.

\section{Related work}
This section will discusse the prior works related to this paper.
As described in Section \ref{app}, UAVs work for data collection using onboard sensors in disaster areas as we assume in this paper.
In Section \ref{cover}, multi-UAV cooperation for area coverage will be discussed; UAVs in our system also work cooperatively to cover a sensing region.
%
Section \ref{compute} will discuss the computing issue of UAVs, which is an important factor in our work though our work assume only cooperative computing with edge server; inter-UAV cooperation for computing is out of scope from this paper.

\subsection{UAV Applications in disaster areas}\label{app}
Transporting relief supplies by UAVs is very important since there is a possibility that humans and ground vehicles cannot easily step into the disaster areas.
Bamburry mentioned the ability of a UAV to deliver medical products to remote and hard-to-reach areas\cite{Bamburry2015}.
For example, in the devastating 2010 earthquake in Haiti, a UAV delivery system was used to deliver medicine to camps set up after the disaster\cite{May2015}.

UAVs can also collect data by using onboard sensors. In \cite{Wada2015}, Each UAV is provided with a mobile optical sensors and image transmission modules developed by the Wada et al. The optical sensor which is a combination of a IR sensor and a visible-light sensor enables data collection even at night or against smoke in the disaster areas.
After the launch, a UAV executes auto flight along the way points by recognizing its positions and  obtains the necessary video/image information. The UAV transmits it to the server and shares it with users via the Internet.

UAVs also often work for forming adhoc wireless mesh network infrastructure, which is called Flying Ad Hoc Networks (FANET)\cite{Bekmezci2013}.
In 2016, S\'anchez et al. aim to provide connectivity for rescuers and disaster victims using UAVs\cite{Garcia2016}.
They propose a Jaccard-based movement rules to define the UAVs best positions for providing the best communication service to the victims in a urban disaster scenario.
Finally they compare among several local search computational intelligence algorithms implemented such as simulated annealing, hill climbing, and random walk for deciding the best tactical UAV movements.

\subsection{Multi-UAV cooperation for area coverage}\label{cover}
Maza et al. provided a pioneer work in cooperatively searching a given area to detect objects of interest by UAVs\cite{Maza2007}.
First they determine relative capabilities of each UAV, based on factors like flight speed, altitude required for the mission, sensitivity to wind conditions and sensing width.
Then, they divide the whole area by divide-and-conquer, taking into account the UAV's relative capabilities and initial locations.
Finally, they set the waypoints of each UAV so that the number of turns needed along a zigzag pattern is minimized.

Zhao et al. in 2016 tackled the challenging problem of not only searching the target area for a lost target but also tracking the target\cite{chang2016}.
In the tracking stage, each UAV keeps desired distance with the target, coordinating the angular separation between neighboring UAVs to the same angle.
if there is a shelter between UAV and target, the target state is predicted by the target model with the former target information.  
In the searching stage, multi-UAVs divide the search region equally which is determined by the target lost duration time and speed and then search for the target by the method of shrinking annulus.
The switch tactics between the tracking stage and the searching stage were also proposed. 

In 2017, Hayat et al. proposed a multi-objective optimization algorithm to search and plan paths for UAVs\cite{Hayat 2017}.
UAVs search for the target cooperatively and soon after some UAV detects the target, the other UAVs takes positions for relay chain formation between the UAV and a base station.
The algorithm aims to minimize the mission completion time, which includes the time to find the target and the time to setup a communication path.
Finally they compare among three strategies that perform search by UAVs in a similar manner but have a different path planning in terms of the mission completion time.

\subsection{Multi-UAV cooperation for computing}\label{compute}
UAV Applications in disaster areas require UAVs to deal with intensive computation tasks such as image/video processing, pattern recognition and feature extraction. 
Computation offloading is very important since computational power of a single UAV is limited.
\subsubsection{Inter-UAV cooperation}
Ouahouah et al. in 2017 proposed the use of offloading mechanism among UAVs equipped with internet-of-thing (IoT) devices\cite{Ouahouah2017}.
Each IoT task is partitioned into a set of sub-tasks that can be executed simultaneously among a cluster of UAVs.
The sub-tasks is assigned to UAVs based on their power supply, resources in terms of memory and CPU computation, and their on-board IoT devices.
Two solutions were proposed for computation offloading:Energy aware optimal task offloading and Delay aware optimal task offloading.
The former maximizes the UAVs lifetime by electing the UAVs with higher power supply.
The latter reduces the response time by favoring the selection of UAVs with more resource capacities.

In 2018, Valentino et al. proposed an opportunistic and adaptive computational offloading scheme between UAV clusters\cite{Valentino2018}.
A cluster head will broadcast a â€˜hello' message indicating their presence and available resources and then a local cluster sends an offloading request to a desired cluster head.
The local cluster decides if it is better to do the task alone or to offload, estimating response time for doing the computational offloading and processing the given task through computing power, size of task, bandwidth, and data rate of wireless network.

\subsubsection{Edge computing}
Edge computing has been proposed as an effective mean of supplementing computational resources for UAVs\cite{Motlagh2017,Messous2017}.

Motlagh et al. in 2017 demonstrated how UAVs can be used for crowd surveillance based on face recognition. 
Due to the computational overhead required by such a use case and given the limited power supply of UAVs, they performed the offloading of video data processing to a mobile edge computing node.
The obtained results showed clearly the benefits of computation offloading compared to the local processing of video data onboard UAVs in saving energy and quickly detecting and recognizing suspicious persons in a crowd.

Messous et al. in 2017 tackled a computation offloading problem with three different devices: UAV, base station and edge server, which carry out the heavy computation tasks.
They proved the existence of a Nash Equilibrium and design an offloading algorithm that converges to the optimal point.
Their cost function was defined as a combination of two performance metrics: energy and delay.
They finally achieved better value of the utility using the the offloading algorithm, compared to computing on: edge server, base station and drone respectively.

\section{Proposed method}\label{method}

\subsection{System overview}\label{sys}
\subsubsection{System model}\label{sysmo}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.0cm]{fig/system_illustration.pdf}
\caption{System illustration}
\label{model}
\end{center}
\end{figure}

Figure \ref{model} depicts the system model we assume in this paper. 
The system consists of a user device (UD), multiple UAVs, and an edge server (ES), the roles of which are described as below.
%
The UD is the central operating entity in the system and operates all the UAVs and the ES; the UD determines flying routes and timings of UAVs and assigns workloads of computing sensor data to UAVs and the ES.
%
The UD also works to forward sensor data received from UAVs to the ES and to obtain computational results from both UAVs and the ES.

Each UAV is operated by the UD and performs the following actions autonomously in the distributed manner.
%
(i) Flying between the initial position, at which the UAV can communicate directly with the UD, and the sensing region assigned to the UAV.
(i\hspace{-.1em}i) Acquiring image data (still or moving images) of the sensing region assigned to the UAV.\\
(i\hspace{-.1em}i\hspace{-.1em}i) Staying at the initial position and performing the following actions in parallel: (a) analyzing a part of collected image data with the computational power of the UAV and (b) delegating the analysis of the rest of the data to the ES.
(i\hspace{-.1em}v) Reporting results obtained from the analysis of image data to the UD soon after it has been completed.
%
Note that we assume that UAVs cannot perform any analysis while flying; computational resources of UAVs are fully used for flight control and image acquiring during the flight. Each UAV repeats all the actions (i) to (i\hspace{-.1em}v). We call one action (i) to (i\hspace{-.1em}v) of some UAV one round.
%
The ES is placed closely to the UD and works to perform the analysis of a part of image data received from UAVs.
%
Like UAVs do, soon after the ES has completed the analysis, it reports the results to the UD.

\subsubsection{System flow}\label{flow}
In the system we assume in this paper, the schedules of flying, acquiring, and analyzing of UAVs are determined through the following steps:
%
\begin{description}
\item[(1)] Check if there is one or more UAVs the schedules of which have not been determined yet. If yes, go to step (2). Otherwise repeat step(1).
\item[(2)] Pick one of the unscheduled UAVs and label it as UAV $i (i=1, 2, 3\cdots)$, if step (1) is yes.
\item[(3)] Refer to the information about the schedules of UAVs $i-1$, $i-2$, $i-3$, $\cdots$, which were scheduled before UAV $i$.
\item[(4)] Determine the schedule of UAV $i$ by a scheduling method, which will be described later.
\item[(5a)] Increment $i$ to $i+1$. Go back to step (1).
\item[(5b)] UAV $i$ starts its operation based on the determined schedule and will be added to the list of unscheduled UAVs after completing all the actions\hspace{-0.5mm} (i) to (i\hspace{-.1em}v) mentioned in Section \ref{sysmo}.
\end{description}
%
Note that (5a) and (5b) are executed in parallel.
%
At step (4), the scheduling method requires some time for calculating the schedule of UAV $i$.
%
The calculating time depends on the complexity of the scheduling method.
%
Therefore, the complexity of the scheduling method should not be complicated.
%
However, during the second or later round of the scheduling for a UAV, the calculation can be done in advance while the UAV is performing step (5b) because all the previous schedules before the UAV have been determined already and the information of all the previous schedules are available.
%
%
When the ES receives a computational task from a UAV via the UD, the ES puts it to the waiting queue.
%
The ES processes those computational tasks in the first-in first-out (FIFO) manner and reports the result to the UD immediately after finishing each computational task.

\subsection{Proposed scheduling method}\label{math}
For simplifying our theoretical discussion, we first assume the system model shown in Figure \ref{model1.5}, in which sensing sections are placed on the one-dimensional line and their sizes are identical.
%
Sensing sections are assigned to UAVs from the one closest to the initial position and only an image is acquired at each sensing section.
%
These assumptions allow us to simply deal with the sensing range of each UAV as the number of images acquired by them.
%
We also assume that, if the computing resource of ES or the communication channel of UD is still used by previously scheduled UAVs (UAVs $1, 2, \cdots i-1$), UAV $i$ has to wait in the FIFO manner until their operations are completed.
%
This also means that the operation of UAV $i$ does not affect the operations of the previous UAVs (UAVs $1, 2, \cdots i-1$).

\begin{figure}[t]
\begin{center}
\includegraphics[width=7.0cm]{fig/onedimention.pdf}
\caption{System model for problem formulation}
\label{model1.5}
\end{center}
\end{figure}

\subsubsection{Utility}\label{to}
This section presents the mathematical formula of the utility function.
%
The utility function of UAV $i$, $U_i$, is given as:

\begin{align}
U_i = \frac{\eta^i}{{\Delta{t}}^i}, \label{ut}
\end{align}
where $\eta^i$ means the efficiency of obtaining results from analyzed data and ${\Delta{t}}^i$ is the interval of obtaining the results.
%
They are called acquisition efficiency and acquisition interval, respectively, and defined as:

\begin{align}
\eta^i&=\frac{N^i}{{t_{fin}^i}-{t_{start}^i}} \label{f1}\\
{\Delta{t}}^i &= {t_{fin}^i}-t_{fin}^{i-1}~~~~(t_ {fin}^0=0, {t_{fin}^i}\geq{t_{fin}^{i-1}}), \label{f2}
\end{align}
where $N^i$ means the number of images acquired by UAV $i$, $t_{start}^i$ is the flight start time of UAV $i$, and $t_{fin}^i$ is the time when processing $N^i$ images is finished.
%
The utility function in defined by (\ref{ut}) suggests that, as the acquisition efficiency and interval become higher and shorter, the system works better for users.
%
The reason why it is reasonable is because, in surveillance scenarios, users would expect to obtain as many pieces of information as possible during a certain period, while more updated information would be more valuable for them.


\subsubsection{Problem formulation}

\begin{table}[t]
\centering
\caption{Definition of notation}
  \begin{tabular}{|c|l|} \hline
 & Description
 \\ \hline
 $N^i$ & No. of images acquired by UAV $i$ \\ \hline
 $N_u^i$ & No. of images processed by UAV $i$ in $N^i$ \\ \hline
 $N_e^i$ & No. of images delegated from UAV $i$ to ES   \\ \hline
 \shortstack[l]{$D$\\ ~}& \shortstack[l]{Distance between initial position and \\left-end of sensing block} \\ \hline
 $d$ & Size of each sensing section     \\ \hline
  $v^{i}$ & Flying speed of UAV $i$    \\ \hline
 $T_g$ & Image acquisition time per sensing section \\ \hline
  $T_{u,d}^{i}(N^i,N_u^i)$ & Transmission waiting time from UAV $i$ to UD  \\ \hline
 \shortstack[l]{$T_{d,e}^{i}(N^i,N_u^i)$\\ ~} & \shortstack[l]{Transmission waiting time of UAV $i$'s data\\from UD to ES}  \\ \hline
 $T_e^{i}(N^i,N_u^i)$ & Processing waiting time at ES  \\ \hline
 \shortstack[l]{$\mu_{u,d}$\\ ~} & \shortstack[l]{Transmission speed from UAV $i$ to UD\\in no. of images per unit time} \\ \hline
 \shortstack[l]{$\mu_{d,e}$\\ ~} &  \shortstack[l]{Transmission speed from UD to ES\\in no. of images per unit time} \\ \hline
 \shortstack[l]{$P_u^i$\\ ~} &  \shortstack[l]{Processing speed at UAV $i$\\in no. of images per unit time} \\ \hline
 \shortstack[l]{$P_e$\\ ~} &   \shortstack[l]{Processing speed at ES\\in no. of images per unit time} \\ \hline
\end{tabular}
\label{para}
\end{table}

This section discusses the problem formulation of the proposed scheduling method.
%
Table \ref{para} lists the definition of the notation we use.
%
In this table, $N^i$, $N_u^i$, and $N_e^i$ are variable.
%
Using the notation, the problem formulation is described as below:

\begin{align}
\argmax_{N^i,N_u^i} \quad&  U_i =\frac{\eta^{i}}{{\Delta{t}}^i}  = \frac{N^i / (t_{fin}^i(N^i,N_u^i)-t_{start}^i)}{t_{fin}^i(N^i,N_u^i)-t_{fin}^{i-1}}\label{eq1}\\
s.t. \quad& {N_{MIN}^i}\leq{N^i}, \label{eq2}
\end{align}
where $N_{MIN}^i$ means that UAV $i$ has to acquire at least $N_{MIN}^i$ images so as not to complete its actions earlier than the previous UAV, UAV $i-1$: ${t_{fin}^i}\geq{t_{fin}^{i-1}}$.
This formulation suggests that $N^i$ and $N_u^i$ must be determined so that the utility function, $U^i$, is maximized.

$t_{fin}^i$ in (\ref{eq1}) is represented as:
\begin{align}
&t_{fin}^i(N^i,N_u^i)=t_{start}^i+\frac{2}{v^i}(D+\sum_{j=1}^{i-1}{N^{j}d})+\nonumber\\
&\hspace{-1mm}N^i({T_g+\frac{d}{v^i}})+\max(\frac{N_u^i}{P_u^i},T_{u,d}^{i}(N^i,N_u^i)+\nonumber\\
&\hspace{-1mm}\frac{N_e^i}{\mu_{u,d}}+T_{d,e}^{i}(N^i,N_u^i)+\hspace{-1mm}\frac{N_e^i}{\mu_{d,e}}+T_{e}^{i}(N^i,N_u^i)+\hspace{-1mm}\frac{N_e^i}{P_e}). \label{eq_fin}
\end{align}

Eliminating $N_e^i$ from (\ref{eq_fin}) using $N^i=N_u^i+N_e^i$, $t_{fin}^i(N^i,N_u^i)$ becomes a function of two variables, $N^i$ and $N_u^i$.
%
According to (\ref{eq_fin}), $t_{fin}^i-t_{start}^i$ is equal to the sum of flight time, transmission time, and processing time of UAV $i$.
%
The second and third terms in the right side of (\ref{eq_fin}) represent the flight time outside the sensing range of UAV $i$ and the sum of the image acquisition time and the flight time within the sensing range assigned to UAV $i$, respectively.
%
The max function of the fourth term in the right side of (\ref{eq_fin}) is the processing time of $N^i$ images, which is equal to the longer one of the image processing time at the UAV $i$ or the total consumed time for image transmission from UAV $i$ to the ES and the image processing at the ES.
%
$T_{u,d}^{i}(N^i,N_u^i)$, $T_{d,e}^{i}(N^i,N_u^i)$, and $T_e^{i}(N^i,N_u^i)$ in the right side of (\ref{eq_fin}) are waiting times for UAV $i$.
%
As we mentioned before, if previous UAVs (UAV1,UAV2,$\cdots$, UAV${i-1}$) are still using the communication channel of the UD or the computational resource of the ES, UAV $i$ has to wait for a certain waiting time until all the transmission and processing tasks have been completed.
%
That is, $t_{fin}^{i-1}$, which is the time when processing $N^{i-1}$ images acquired by UAV $i-1$ is finished, is not affected by the operation of UAV $i$ and can be dealt as a constant value in the scheduling of UAV $i$.
%
Note that we assumed, since the size of output data obtained after processing at UAVs and the ES is quite small, transmission time of those output data is negligible.

$N_{MIN}^i$ in (\ref{eq2}) is the specific value of $N^i$ that satisfies the following condition:
%
\begin{align}
\argmin_{N^i,N_u^i} \quad& {t_{fin}^i(N^i,N_u^i)}\label{eq_min1}\\
s.t. \quad& {t_{fin}^i(N^i,N_u^i)}\geq{t_{fin}^{i-1}}({N_u^i}\in \mathbb{N}\mid 0\leq{N_u^i}\leq{N^i}). \label{eq_min2}
\end{align}
%
Here, suppose that ${N_u^i}$ is determined so as to minimize $t_{fin}^i(N^i,N_u^i)$ for a given $N^i$.
%
For such ${N_u^i}$, $N_{MIN}^i$ is the minimum integer among possible values of $N^i$ that satisfy Formula (\ref{eq_min2}).
%
By setting $N_{MIN}^i$ so, as long as ${N_u^i}$ is chosen so as to satisfy $0\leq{N_u^i}\leq{N^i}$, the optimal $N^i$ in (\ref{eq1}) can be determined among the possible values of $N^i$ that satisfy $U^i$(=$\frac{\eta^{i}}{{\Delta{t}}^i}) > 0$.

The solution for (\ref{eq1}) and (\ref{eq2}) is mentioned in detail in APPENDIX \ref{ape}.

\subsection{Requirements of scheduling for multi-UAV search system} \label{feature}
From a user-centric viewpoint, the scheduling of multi-UAV search systems should satisfy the four requirements described below.
\begin{itemize}
\item Robustness for the increase or decrease of number of UAVs: 
The number of UAVs may increase due to adding the new UAVs to the existing UAV group or decrease due to the breakdown of the UAVs. 
If there is new UAVs, they are added to the group of the unscheduled UAVs in (1) of the system flow mentioned in Section \ref{flow}.
If some UAV turns out to be broken on the way, the UAVs which will start the operations after that are rescheduled: these UAVs   are added to the group of the unscheduled UAVs in (1) of the system flow.
%
\item Applicability for the heterogeneity of UAVs: 
There are individual differences in the flying speed and the processing speed of each UAV. 
In our proposed scheduling method, such individual differences is considered in (\ref{eq_fin}).
%
\item Applicability for the various kinds of processing capacities of UAVs and ES: 
The computational performance of each UAV and ES depends greatly on the machine capability. In the proposed method, it is possible to efficiently utilize the computing capacity of each UAV and ES, since $t_{fin}^i(N^i,N_u^i)$ in (\ref{eq_fin}) is defined considering the machine performance.
%
\item Feasibility for extension to various types of geographical areas: 
There are many kinds of geographical areas in practical situations.
As we will discuss shortly in Section \ref{twodi}, by extending one-dimensional model as shown in Fig. \ref{model1.5}, our proposed scheduling method is applicable for two-dimensional models.
It is obvious that the extension to three-dimensional models can be also considered though the detail is not presented in this paper.

by converting the three dimensional data of such area into the two-dimensional model, which will be described later 
\end{itemize}

\section{Basic performance evaluation}\label{eva}
This section shows that the proposed scheduling method maximizes the user's utility through the basic performance evaluation.
\subsection{Simulation scenario}
We considered a surveillance scenario in which a rescue team uses the multi-UAV system illustrated in Figure \ref{model} to find missing people in an area where humans and ground vehicles cannot easily step into.
%
We here assumed a simple model illustrated in Figure \ref{model1.5}, in which sensing sections are placed on the one-dimensional line and their sizes are identical, to present the problem formulation.
%
Our simulation adopted the proposed scheduling method described in Section \ref{math} and performed every step of the system flow described in Section \ref{flow}.
%
We compared the proposed method with one of the existing methods: fixed method, which simply assigns a fixed number of sensing sections to each UAV uniformly \cite{chang2016}.
In the fixed method, $N_u^i$ is determined so that $t_{fin}^i$ is minimized.
%
In our basic evaluation, we assumed that the user cumulatively obtains $U_i$, which is defined by (\ref{ut}), every time UAV $i$ finishes its one round at $t_{fin}^i$.
%
Then, we observe how the cumulative summation of $U_i$ increases as the time elapses after the first UAV has started flying.
%

\subsection{Simulation parameters}

The parameters used in our simulation are listed in Table \ref{para_val}.
%
Considering the realistic specification of a recently commercialized UAV \cite{bebop2}, we set the flying speed of UAVs to 15 m/s.
%
The size of images was set to 100 kbytes, which corresponds to the one in the dataset called PASCAL VOC 2007 used in \cite{Ren2015}.
%
The consumed times for processing one image at UAVs and the ES are set corresponding to the consumed time for object recognition using GPU and CPU reported in \cite{Ren2015}, respectively.
As described in Section \ref{feature}, we need to consider the heterogeneity of UAVs from a user-centric viewpoint.
Therefore, the flying speed of and the number of images processed by UAVs were given by the normal distributions where the mean and the deviation were $\mu$ and $\sigma$. We set $\sigma$ = 0.1$\mu$ and the upper and lower limits to $\mu+2\sigma$ and $\mu-2\sigma$, respectively.
%
The transmission rates of communication channel from UAVs to the UD and from the UD to the ES are set 100 Mbps, which is similar to the effective throughput of IEEE802.11n \cite{Li2013}.
%

\subsection{Results}
Figures \ref{utility} (a) and \ref{utility} (b) plots cumulative sum of utilities against elapsed time after start time with $D$=200 and $D$=600, respectively.
We examined the fixed method with $N^i$ = 1, 10, 40, and 80.
As we see in the figures, cumulative sum of utilities in all the methods keeps almost constant and then increase as time passes.
Cumulative sum of utilities in the proposed method is the largest at any elapsed time, which suggests that the proposed method worked better than the fixed method in terms of cumulative sum of utilities.
\begin{figure*}[t]
\begin{center}
\includegraphics[width=16.0cm]{fig/totalutility.png}
\caption{Cumulative sum of utilities}
\label{utility}
\end{center}
\end{figure*}

\begin{table}
  \begin{center}
    \caption{Simulation parameters}
    \label{para_val}
    \begin{tabular}{ll}
     \hline
Parameters & value \\ \hline
No. of UAVs ($U$) & 5\\
Average flying speed of UAVs & 15 m/s \\
\shortstack[l]{Distance from initial position \\to left-end of sensing block ($D$)} & \shortstack[l]{200,600m\\~}  \\ 
Size of each sensing section ($d$) & 5 m  \\ 
Consumed time for acquiring one image & 2 s \\ 
Transmission rate of communication channel & 100 Mbps \\ 
Size of image  &  100 kbytes \\ 
\shortstack[l]{Average processing speed at UAVs \\in no. of images per unit time ($\overline{P_u}$)} & \shortstack[l]{$\frac{1}{1.83}$\\~} \\ 
\shortstack[l]{Processing speed at ES in no. of images \\per unit time ($P_e$)} & \shortstack[l]{$\frac{1}{0.198}$\\~} \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\section{EVALUATION FROM USER-CENTRIC VIEWPOINT}
In this section, we adopted the three evaluation metric to discuss our proposed scheduling method from a user-centric viewpoint.

\subsection{Extension to two-dimensional model}\label{twodi}
Before introducing the evaluation metrics, we introduce the two-dimensional model we used for the evaluation.
The following two assumptions make our proposed scheduling method described in Section \ref{math} easily applicable for two-dimensional models.
\ref{twodimention} :

\begin{description}

\item[(1)]  Assuming fan-shaped sensing region, split the region so that each sensing section range is constant
\item[(2)] Each UAV executes sensing on the zigzag in order from the area closest to the center like \cite{Maza2007}
\end{description}

In Figure \ref{twodimention}, the vertical width of each partition is $d$ and the central angle of the sensing region is $\theta$ [rad].
Then, the distances between each neighboring section is $d$ for the direction opposite to the center of the region, while the ones between each neighboring section for the circumference is $\frac{1}{2}d\theta$.
Therefore, when $\theta=2$ [rad], all the distances between each neighboring section become equal to $d$ as shown in Figure \ref{model1.5}.
Then, since the two-dimensional model in Figure \ref{model1.5} can be dealt same as the one-dimensional model, the proposed scheduling method is easily applicable.

\begin{figure}[t]
\begin{center}
\includegraphics[width= 7cm]{fig/twodim.png}
\caption{Sensing region of two-dimensional model}
\label{twodimention}
\end{center}
\end{figure}

\subsection{Evaluation metrics}\label{compare}
We used the following three evaluation metrics from a user-centric viewpoint.

\paragraph*{Two types of elapsed times}
The first elapsed time is `elapsed time from start time' for each image, which is the elapsed time since the first UAV starts flying until the result about each image is obtained by the UD.
%
This metric is important for the rescue team because they need to know the information about each sensing section as soon as possible to know whether missing people are there or not.
%
The second one is `elapsed time after acquired' for each image, which is the elapsed time since an image is acquired at the corresponding sensing section until the result about the image is obtained by the UD.
%
This metric is also valuable for the rescue team because it indicates the freshness of the information about each sensing section; the less updated information, the less reliable for them in searching missing people.

\paragraph*{No. of images satisfying time requirement}
The second metric is number of images satisfying time requirement: the number of images that satisfy shorter elapsed time after acquired than a predetermined threshold at a certain time.
This metric is important for the rescue team because they need to get the fresh information while obtaining as many pieces of information as possible for a certain period.

\paragraph*{Information value obtained by user}
The third metric is cumulative summation of information valueobtained by the user at each time.
In \cite{NOMURA2001}, the value function of the obtained image $j$ at a elapsed time from start time $t$ was given as:
\begin{align}
V_j=2^{-\frac{t}{T_{half}}}, \label{eq_value}
\end{align}
where $T_{half}$ means the half-life of the value, which is a parameter set according to the time requirement in the disaster situation.
%
The user gets $V_j$ when obtaining the result from processed image $j$. 
This metric allows us to measure how much valuable information the user has obtained before the rescue team actually start their rescue. 

\subsection{result}

\begin{figure}[t]
\begin{center}
\includegraphics[width=8cm]{fig/elapsedtime.png}
\caption{Two types of elapsed times}
\label{elapsed}
\end{center}
\end{figure}

\begin{figure*}[t]
\begin{center}
\includegraphics[width=18.0cm]{fig/noimage.png}
\caption{No. of images that shorter elapsed time after acquired than 120 [s] at 600 [s] after start time}
\label{totalnumber}
\end{center}
\end{figure*}

\begin{figure*}[t]
\begin{center}
\includegraphics[width=18.0cm]{fig/totalvalue.png}
\caption{Cumulative sum of values}
\label{totalvalue}
\end{center}
\end{figure*}

Figure \ref{elapsed} (a) plots the elapsed time from the start time for acquired images against each area id.
In Fig. \ref{elapsed} (a), as the area id increases, the elapsed time from start time monotonically increases in all the methods.
In the fixed method, as the area id increased, $N^i$ giving the shortest elapsed time from the start time became larger for each area id.
The proposed method worked between the fixed method with $N^i=10$ and $N^i=40$.
%
On the other hand, Figure \ref{elapsed} (b) plots the elapsed time after acquired for each image.
The elapsed time after acquired decreases with some regular pattern in all the methods.
However, in the fixed method, as $N^i$ was set smaller, the elapsed time after acquired became shorter.
The proposed method worked between the fixed method with $N^i=10$ and $N^i=40$.
%
In the fixed method, $N^i=10$ and $N^i=40$ are reasonable; the elapsed times from start time of them were between the best and the third best, while their elapsed times after acquired were much shorter than that of $N^i=80$.
%
The proposed method worked between the fixed method with $N^i=10$ and $N^i=40$ in both types of elapsed times, which suggests that it enables us to automatically achieve the reasonable $N^i$.

Figures \ref{totalnumber} (a), \ref{totalnumber} (b), and \ref{totalnumber} (c) plot the numbers of images that satisfied shorter elapsed time after acquired than 120 [s] at 600 [s] against the processing speed at ES in no. of images per unit time, the number of UAVs, and the distance from the initial position to the closest sensing block (area id = 1), respectively.
The plots are obtained by averaging the results obtained from three trials.
In the left side of Figure \ref{totalnumber} (a), the processing speed at ES is sufficiently lower than the average processing speed at UAVs, which corresponds to the case where processing is performed mainly at UAV not so using ES.
In the right side of Figure \ref{totalnumber} (a), the average processing speed at UAV is sufficiently lower than the processing speed at ES, which corresponds to the case where processing is performed mainly at ES not so using UAV.
In Figures \ref{totalnumber} (a) and (b), the proposed method works at the sufficient level for different values of $\frac{P_e}{\overline{P_u}}$ and $U$, while different $N^i$ is the best for different parameters in the fixed method.
In Figure \ref{totalnumber} (c), the proposed method keep working at the sufficient level for different values of $D$, while no. of images in the fixed method monotonically decreases, as $D$ is set larger.

Figure \ref{totalvalue} plots the cumulative sum of values against the elapsed time from start time.
The half-life of Figure \ref{totalvalue}(a), \ref{totalvalue}(b), and \ref{totalvalue}(c) is 30, 60, and 120 [s], respectively.
In these figures, the cumulative sum of values monotonically increases in all the methods.
The proposed method works at the sufficient level for a wide variety of half-lifes, while different $N^i$ is the best for different half-lifes in the fixed method.

From the result of Figure \ref{totalnumber} and Figure \ref{totalvalue}, since the proposed method works at the sufficient level without setting the reasonable $N^i$ according to the parameter unlike the fixed method, we can conclude that the proposed method works best in this evaluation scenario.


\section{CONCLUSION}
This paper proposed a scheduling method of multi-UAV search system that, from a user-centric viewpoint, considers processing time of the acquired image data and data transfer time in areas where humans and ground vehicles cannot easily step into like disaster-damaged areas.
In this paper, we first showed the system model, which consists of a user device, multiple UAVs, and an edge server, and mentioned the sytem flow. 
We then presented the utility-based problem formulation that ensures the freshness of individual obtained piece of information while obtaining as many pieces of information as possible for a certain period.
The result of the basic performance evaluation was presented to verify that in terms of cumulative sum of utilities, the proposed method worked better than the existing methods: fixed method, which simply assigns a fixed number of sensing sections to each UAV uniformly.
In addition, the simulation using the three evaluation metrics showed that the proposed method works at the sufficient level from a user-centric viewpoint.
Future work includes the practical implementation.

\appendices
\section{Solution of the problem formulation}\label{ape}
It takes long time to solve (4) and (5) due to their computational complexities and the calculation for scheduling could be non-negligible overhead in the system; UAVs have to wait to start flying until their schedules have been determined.
Therefore, to simplify the calculation of (\ref{eq1}) and (\ref{eq2}), our scheduling method first supposes that all the waiting times for UAV $i$ are equal to zero and obtains an approximated solution, $N_{th}^i$.
Then, by searching locally around $N_{th}^i$, our scheduling method considers all the waiting times in (\ref{eq1}) and (\ref{eq2}) and finds out the local optimal solution, $N_{l}^i$.
The following part explains the way of finding out $N_{th}^i$.
%
First, we set all the waiting times to zero.
%
Then, we replace the second and fourth terms in (\ref{eq_fin}) with $2F$ and $M$, respectively.
%
Then, by substituting ${t_{fin}^i}$ in (\ref{eq_fin}) to (\ref{ut}), we obtain $\frac{\eta^i}{{\Delta{t}}^i}$ as below:
%
\begin{align}
\frac{\eta^{i}}{{\Delta{t}}^i}
=&\frac{N^i}{N^i({T_g}+\frac{d}{v^i})+2F+M}\times\nonumber\\
&\frac{1}{N^i({T_g}+\frac{d}{v^i})+2F+M+t_{start}^i-t_{fin}^{i-1}}\label{eq4}
\end{align}
%
where, by regarding $N^i$ as a constant, only $M$ is a variable and the value of $\frac{\eta^{i}}{{\Delta{t}}^i}$ varies dependently on the values of $N_u^i$ and $N_e^i$.
%
Since $\frac{\eta^{i}}{{\Delta{t}}^i}$ is always positive,  $M$ takes the minimum when $\frac{\eta^{i}}{{\Delta{t}}^i}$ takes the maximum. 
%
Although $N^i$, $N_u^i$, and $N_e^i$ are integers, here we deal with them as real numbers.
%
Considering $N^i=N_u^i + N_e^i$, on the assumption that $\frac{N_u^i}{P_u^i}$ equals to $\frac{N_e^i}{\mu_{u,d}}+\frac{N_e^i}{\mu_{d,e}}+\frac{N_e^i}{P_e}$, we can obtain the value of $N_u^i$ and $N_e^i$ that satisfy $0\leq{N_u^i}$ and ${N_e^i}\leq{N^i}$ as follows:
%
\begin{align}
N_u^i=\frac{P_u^i(\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e})}{\mu_{u,d}\mu_{d,e}P_e+P_u^i(\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e})}N^i\label{eq5}\\
N_e^i=\frac{\mu_{u,d}\mu_{d,e}P_e}{\mu_{u,d}\mu_{d,e}P_e+P_u^i(\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e})}N^i\label{eq6}
\end{align}
%
When $M$ takes the minimum value, $\frac{N_u^i}{P_u^i}$ is theoretically equal to $\frac{N_e^i}{\mu_{u,d}}+\frac{N_e^i}{\mu_{d,e}}+\frac{N_e^i}{P_e}$, while $N_u^i$ and $N_e^i$ become (\ref{eq5}) and (\ref{eq6}), respectively.
%
As $N^i$ becomes larger, $\frac{N_u^i}{P_u^i}$ is closer to $\frac{N_e^i}{\mu_{u,d}}+\frac{N_e^i}{\mu_{d,e}}+\frac{N_e^i}{P_e}$.
%
Thus, $\frac{N_u^i}{P_u^i}=\frac{N_e^i}{\mu_{u,d}}+\frac{N_e^i}{\mu_{d,e}}+\frac{N_e^i}{P_e}$ is established.\\
%
As a result, $\frac{\eta^{i}}{{\Delta{t}}^i}$ in (\ref{eq4}) is given as:
%
\begin{align}
&\hspace{-0.2cm}\frac{N^i}{R^2{(N^i)}^2+(4F+t_{start}^i-t_{fin}^{i-1})R{N^i}+2F(2F+t_{start}^i\hspace{-1mm}-t_{fin}^{i-1})}\hspace{1cm}\label{eq_ec}\\
&\hspace{-0.6cm}\biggl(R=T_g+\frac{d}{v^i}+\frac{\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e}}{\mu_{u,d}\mu_{d,e}P_e+P_u^i(\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e})}\biggr)\nonumber
\end{align}
%
To sketch (\ref{eq_ec}), by differentiating it by $N^i$, we obtain:
%
\begin{align}
\hspace{-4mm} \frac{-{R^2{(N^i)}^2}+2F(2F+t_{start}^i\hspace{-1mm}-t_{fin}^{i-1})}{\{R^2{(N^i)}^2+(4F+t_{start}^i\hspace{-1mm}-t_{fin}^{i-1})R{N^i}+2F(2F+t_{start}^i\hspace{-1mm}-t_{fin}^{i-1})\}^2}
\end{align}
%
When $t_{start}^i \leq{t_{fin}^{i-1}-2F}$, (\ref{eq_ec}) decreases monotonically as the value of $N^i$ increases and takes the maximum when $N_{th}^i$ is $N_{MIN}^i$.
%
When $t_{start}^i >{t_{fin}^{i-1}-2F}$, $\frac{\eta^{i}}{{\Delta{t}}^i}$ is a convex function taking the maximum when $N^i$ is $\frac{\sqrt{2F(2F+t_{start}^i-t_{fin}^{i-1})}}{R}$.
%
Note that $N^i$ is chosen so that the denominator of (\ref{eq_ec}) does not become zero.
%
Through the above procedures, we can obtain $N_{th}^i$ as follows:
%
\begin{align}
 \hspace{-1.5mm} N_{th}^i= \begin{cases}
    \frac{\sqrt{2F(2F+t_{start}^i-t_{fin}^{i-1})}}{R} & ({N_{MIN}^i}\leq{\frac{\sqrt{2F(2F+t_{start}^i-t_{fin}^{i-1})}}{R}}) \\
    N_{MIN}^i& (\frac{\sqrt{2F(2F+t_{start}^i-t_{fin}^{i-1})}}{R}<{N_{MIN}^i})
  \end{cases}
\end{align}

In finding out the local optimal solution, $N_{l}^i$, the range of local searching in the proposed scheduling method was set enough wide so that it can ensure that the local optimal solution equals to the true optimal solution.
%
In addition, we assumed that the consumed time for finding out the local optimal solution is negligible; since the complexity of the scheduling algorithm is quite simple, the calculation can be finished in advance while the UAV is flying in the previous round.

\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\begin{thebibliography}{1}
\bibitem{CRED2016}Debarati Guha-Sapir, Philippe Hoyois, Pasacline Wallemacq and Regina Below,``Annual Disaster Statistical Review 2016,"\emph{Centre for Research on
the Epidemiology of Disasters},2016 
\bibitem{disaster2011} Japan Ministry of Defense, ``Lessons from the Great East Japan Earthquake," \url{http://www.mod.go.jp/e/publ/w_paper/pdf/2012/30_Part3_Chapter1_Sec3.pdf}, 2012
\bibitem{Andre2014} T. Andre, K. Hummel, A. Schoellig, E. Yanmaz, M. Asadpour, C. Bettstetter, P. Grippa, H. Hellwagner, S. Sand and S. Zhang, ``User devicelication-driven design of aerial communication networks, " \emph{IEEE Commun. Mag.}, vol. 52, no. 5, pp. 129-137, 2014
\bibitem{Erdelj2016} M. Erdelj, and N. Enrico, ``UAV-assisted disaster management: User devicelications and open issues, " \emph{2016 International Conference on Computing, Networking and Communications (ICNC)},pp1-5, 2016
\bibitem{Felice2014} M. Di Felice, A. Trotta, L. Bedogni, K. R. Chowdhury and L. Bononi, ``Self-organizing aerial mesh networks for emergency communication, " \emph{Personal, Indoor, and Mobile Radio Communication (PIMRC), IEEE 25th Annual International Symposium on}, pp. 1631-1636, 2014
\bibitem{japan2011}Armand Vervaeck and James Daniell,``Japan Tohoku tsunami and earthquake : The death toll is climbing again!, " \url{https://earthquake-report.com/2011/08/04/japan-tsunami-following-up-the-aftermath-part-16-june/}, 2011
\bibitem{Lanillos2014} P. Lanillos, S. K. Gan, E. Besada-Portas, G. Pajares and S. Sukkarieh, ``Multi-UAV target search using decentralized gradient-based negotiation with expected observation,"\emph{Information Sciences}, vol. 282, pp. 92-110, 2014.
\bibitem{Maza2007} I. Maza, A. Ollero, ``Multiple UAV cooperative searching operation
using polygon area decomposition and efficient coverage algorithms, "\emph{Distributed Autonomous Robotic Sys-tems}, pp. 221-230, 2007.
\bibitem{Meng2014} W. Meng, Z. R. He, R. Teo, L. xie, ``Decentralized Search, Tasking and Tracking Using Multiple Fixed-Wing Miniature UAVs," \emph{11th IEEE
International Conference on Control \& Automation (ICCA)}, pp. 1345-1350, 2014 
\bibitem{chang2016} C. Zhao, M. Zhu and H. Liang, ``The Sustainable Tracking Strategy of Moving Target by Multi-UAVs in an Uncertain Environment, " \emph{2016 IEEE/CSAA International Conference on Aircraft Utility Systems (AUS)}, pp. 20-25, 2016
\bibitem{Mirzaei2011} M. Mirzaei, F. Sharifi, B. W. Gordon, C. A. Rabbath and  Y. M.Zhang, ``Cooperative multi-vehicle search and coverage problem in uncertain environments, "\emph{in Proceedings of the 50th IEEE Conference on Decision and Control and European Control Conference (CDCECC)}, pp. 4140-4145, 2011
%
\bibitem{GCCE2018}  K. Miyano, R. Shinkuma, E. Oki, and T. Sato, ``Utility Based Scheduling for Multi-UAV Search System in Disaster Scenarios,'' Proc. IEEE 7th Global Conference on Consumer Electronics (GCCE), Aug 2018.
\bibitem{Bamburry2015} D. Bamburry, ``Drones: Designed for product delivery," \emph{Design Management Review}, vol. 26, no. 1, pp. 40-48, 2015
\bibitem{May2015}K. May,``Drones to deliver medicine and food? Drones for disaster relief? Why not?,"\url{https://ideas.ted.com/6-ways-drones-can-be-used-for-good/}, 2013
\bibitem{Wada2015}A. Wada, T. Yamashita, M. Maruyama, T. Arai, H. Adachi and H. Tsuji, ``A surveillance system using small unmanned aerial vehicle (UAV) related technologies,''\emph{NEC Technical Journal},vol.8, no. 1, p68-72, 2015
\bibitem{Bekmezci2013} I. Bekmezci, O. K. Sahingoz, and S. Temel, ``Flying Ad-Hoc Networks (FANETs): a survey,''\emph{Ad Hoc Networks}, vol. 11, no. 3, pp. 1254-1270, 2013
\bibitem{Garcia2016} J S\'anchez-Garc\'ia, JM Garc\'ia-Campos, SL Toral, DG Reina and F Barrero, ``An intelligent strategy for tactical movements of UAVs in disaster scenarios,''\emph{
International Journal of Distributed Sensor Networks}, vol.12, no. 3, 2016
\bibitem{Hayat 2017}S. Hayat, E. Yanmaz, T. X. Brown, and C. Bettstetter,``Multi-Objective UAV Path Planning for Search and Rescue,''\emph{ICRA Singapore}, 2017 
%
\bibitem{Ouahouah2017}S. Ouahouah , T. Taleb, J. Song and C. Benzaid, ``Efficient offloading mechanism for UAVs-based value added services," \emph{IEEE International Conference on Communications (ICC)}, 2017
\bibitem{Valentino2018} R. Valentino, W.-S. Jung and Y.-B. Ko,``Opportunistic Computational Offloading System for Clusters of Drones,''\emph{International Conference on Advanced Communications Technology(ICACT)}, 2018 
%
\bibitem{Motlagh2017}N. H. Motlagh, M. Bagaa, and T. Taleb, ``Uav-based iot platform: A crowd surveillance use case,''\emph{IEEE Communications Magazine}, vol.55, no.2, pp. 128-134, 2017
%
\bibitem{Messous2017} M.-A. Messous1, A. Arfaoui, A. Alioua, S. -M. Senouci,``A Sequential Game Approach for Computation-Offloading in an UAV Network,''\emph{IEEE Global Communications Conference}, 2017 
\bibitem{bebop2} Parrot SA, ``PARROT BEBOP2 SO LIGHT YOU CAN TAKE IT
ANYWHERE TO FILM IN FULL HD, "
\url{http://www.parrot.com/usa/products/bebop2/}, 2016
%
\bibitem{Ren2015} S. Ren, K. He, R. Girshick, J. Sun, ``Faster R-CNN: Towards
real-time object detection with region proposal networks,'' \emph{In Advances in neural information processing systems}, pp. 91-99, 2015
\bibitem{Li2013} J. Li, Y. Fan, H. Chen, K. Xu, Y. Dai, F. Yin, Y. Ji,  ``Radio-over-fiber-based distributed antenna systems supporting IEEE 802.11 N/AC standards,'' \emph{Optical Communications and Networks (ICOCN), 2013 12th International Conference on. IEEE}, pp. 1-4, 2013
\bibitem{NOMURA2001}K. NOMURA, K. YAMORI, E. TAKAHASHI, T. MIYOSHI, and Y. TANAKA, ``Waiting time versus utility to download images.,"  \emph{4th Asia Pacific-Symposium on Information and Telecommunication Technologies}, pp. 128-132, 2001 

\end{thebibliography}



\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Kosei Miyano} received the B.E. degree in Electrical
and Electronic Engineering from Kyoto University,
Kyoto, Japan, in 2017. He is currently a
master course student of Communications and
Computer Engineering, Graduate School of Informatics,
Kyoto University. His research interest
is adaptive operation for unmanned aerial vehicles.
\end{IEEEbiography}



\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Ryoichi Shinkuma} received the B.E., M.E., and
Ph.D. degrees in Communications Engineering
from Osaka University, Japan, in 2000, 2001, and
2003, respectively. In 2003, he joined the faculty
of Communications and Computer Engineering,
Graduate School of Informatics, Kyoto University,
Japan, where he is currently an Associate Professor. He was a Visiting Scholar at Wireless Information Network Laboratory (WINLAB), Rutgers,
the State University of New Jersey, USA, from
2008 Fall to 2009 Fall. His research interests include network design and
control criteria, particularly inspired by economic and social aspects. He
received the Young Researchers' Award from IEICE in 2006 and the Young
Scientist Award from Ericsson Japan in 2007, respectively. He also received
the TELECOM System Technology Award from the Telecommunications
Advancement Foundation in 2016. He has been the chairperson of the
Mobile Network and Applications (MoNA) Technical Committee of IEICE
Communications Society since June 2017. He is a member of IEEE.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Narayan B. Mandayam} (S'89-M'94-SM'99-F'09) received the B.Tech (Hons.) degree in 1989
from the Indian Institute of Technology, Kharagpur, and
the M.S. and Ph.D. degrees in 1991 and 1994 from Rice
University, all in electrical engineering. Since 1994 he has
been at Rutgers University where he is currently a Distinguished
Professor and Chair of the Electrical and Computer
Engineering department. He also serves as Associate Director
at WINLAB. He was a visiting faculty fellow in the Department
of Electrical Engineering, Princeton University, in
2002 and a visiting faculty at the Indian Institute of Science,
Bangalore, India in 2003. Using constructs from game theory,
communications and networking, his work has focused
on system modeling, information processing and resource
management for enabling cognitive wireless technologies to
support various applications. He has been working recently
on the use of prospect theory in understanding the psychophysics
of pricing for wireless data networks as well as
the smart grid. His recent interests also include privacy in
IoT, resilient smart cities as well as modeling and analysis of
trustworthy knowledge creation on the internet. Dr. Mandayam
is a co-recipient of the 2015 IEEE Communications
Society Advances in Communications Award for his seminal
work on power control and pricing, the 2014 IEEE Donald
G. Fink Award for his IEEE Proceedings paper titled
``Frontiers of Wireless and Mobile Communications''and
the 2009 Fred W. Ellersick Prize from the IEEE Communications
Society for his work on dynamic spectrum access
models and spectrum policy. He is also a recipient of the
Peter D. Cherasia Faculty Scholar Award from Rutgers University
(2010), the National Science Foundation CAREER
Award (1998) and the Institute Silver Medal from the Indian
Institute of Technology (1989). He is a coauthor of the
books: Principles of Cognitive Radio (Cambridge University
Press, 2012) and Wireless Networks: Multiuser Detection
in Cross-Layer Design (Springer, 2004). He has served
as an Editor for the journals IEEE Communication Letters
and IEEE Transactions on Wireless Communications. He
has also served as a guest editor of the IEEE JSAC Special
Issues on Adaptive, Spectrum Agile and Cognitive Radio
Networks (2007) and Game Theory in Communication Systems
(2008). He is a Fellow and Distinguished Lecturer of
the IEEE.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Takehiro Sato} received the B.E. and M.E. degrees from Keio
University, Japan, in 2010 and 2011, respectively. He is currently
working toward the Ph.D. degree at the Graduate School of Science
and Technology, Keio University, Japan. His research interests include
communication protocols and network architectures for the
next-generation optical network. From 2011 to 2012, he was a research
assistant in the Keio University Global COE Program,
``High-Level Global Cooperation for Leading Edge Platform on
Access Spaces,â€ by the Ministry of Education, Culture, Sports,
Science, and Technology, Japan. He is currently a research fellow
of the Japan Society for the Promotion of Science (since 2012). He is
a student member of the IEEE and the IEICE.
\end{IEEEbiography}


\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Eiji Oki} (M'95\UTF{2013}SM'05\UTF{2013}F'13) received the B.E. and
M.E. degrees in instrumentation engineering and the
Ph.D. degree in electrical engineering from Keio
University, Yokohama, Japan, in 1991, 1993, and
1999, respectively. In 1993, he joined the Nippon
Telegraph and Telephone Corporation (NTT) Communication
Switching Laboratories, Tokyo, Japan,
where he was involved in researching network
design and control, traffic control methods, and highspeed
switching systems. From 2000 to 2001, he
was a Visiting Scholar with the Polytechnic Institute
of New York University, Brooklyn, NY, USA, where he was involved in
designing terabit switch/router systems. He was engaged in researching
and developing high-speed optical IP backbone networks with the NTT
Laboratories. He joined The University of Electro-Communications, Tokyo,
in 2008, where he is currently a Professor. He has been active in the
standardization of the path computation element and GMPLS in the IETF.
He has authored over ten IETF RFCs. He has authored/coauthored four
books, Broadband Packet Switching Technologies (Wiley, 2001), GMPLS
Technologies (CRC Press, 2005), Advanced Internet Protocols, Services, and
Applications (Wiley, 2012), and Linear Programming and Algorithms for
Communication Networks, (CRC Press, 2012). He is a Fellow of the IEICE.
He was a recipient of several prestigious awards, including the 1998 Switching
System Research Award and the 1999 Excellent Paper Award presented by
IEICE, the 2001 Asia-Pacific Outstanding Young Researcher Award presented
by IEEE Communications Society for his contributions to broadband network,
ATM, and optical IP technologies, the 2010 Telecom System Technology
Prize by the Telecommunications Advanced Foundation, the IEEE HPSR 2012
Outstanding Paper Award, the IEEE HPSR 2014 Best Paper Award Finalist,
the First Runner Up, and the 2015 IEICE Achievement Award.
\end{IEEEbiography}



\EOD


\end{document}


