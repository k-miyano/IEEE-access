\documentclass{ieeeaccess}

\usepackage[dvipdfmx]{graphicx}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{comment}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{amsmath,amssymb,,amsfonts}
\usepackage{ascmac}
\usepackage{bm}
\usepackage{cite}
\usepackage{nidanfloat}
\usepackage{url}
\usepackage{color}
\usepackage{algorithmic}
\usepackage{textcomp}

\usepackage[utf8]{inputenc}
\usepackage[whole]{bxcjkjatype}
\usepackage{xcolor}

\def\rnum#1{\expandafter{\romannumeral #1}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newcommand{\argmin}{\mathop{\rm arg~min}\limits}
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}


\begin{document}
\history{Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.}
\doi{10.1109/ACCESS.2017.DOI}
\title{Utility Based Scheduling for Multi-UAV Search Systems in Disaster-hit Areas}

\author{\uppercase{Kosei MIYANO\authorrefmark{1}, Ryoichi SHINKUMA\authorrefmark{1}, NARAYAN B. MANDAYAM\authorrefmark{2}, Takehiro SATO\authorrefmark{1}, and Eiji OKI\authorrefmark{1}}}
\address[1]{Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto 606-8501, Japan}
\address[2]{Wireless Information Network Laboratory (WINLAB), Rutgers University, 671 Route 1 South, North Brunswick, NJ, 08902-3390, USA}
\tfootnote{This work was partly supported by JSPS KAKENHI Grant Number JP17H01732.}

\markboth
{K. Miyano \headeretal: Utility Based Scheduling for Multi-UAV Search Systems in Disaster-hit Areas}
{K. Miyano \headeretal: Utility Based Scheduling for Multi-UAV Search Systems in Disaster-hit Areas}

\corresp{Corresponding author: K. Miyano (e-mail: kmiyano@icn.cce.i.kyoto-u.ac.jp).}

\begin{IEEEkeywords}
unmanned aerial vehicle, target search, scheduling, edge computing
\end{IEEEkeywords}

\begin{abstract}
Using micro or small unmanned aerial vehicles (UAVs) is a promising solution for finding people who have disappeared during unexpected situations such as disasters.
 It takes a long time to analyze the acquired image data for target recognition due to the limited computational resources of small UAVs with image sensors.
In addition, the data-transfer time can increase in disaster-hit areas due to damage to communication infrastructures. However, prior studies did not consider both the processing time of the acquired data and data transfer time.  From a user-centric viewpoint, however, the temporal requirements in such surveillance scenarios is strict.Therefore, we propose a scheduling method of multi-UAV search systems that takes into account the processing time of image data and data-transfer time. We present the utility-based problem formulation that ensures the freshness of each piece of obtained information while obtaining as many pieces of information as possible for a certain period. Simulation results indicate that the proposed scheduling method maximizes user utility and performs better than [a conventional scheduling method?] in terms of user-centric evaluation metrics.

\end{abstract}

\maketitle
\IEEEpeerreviewmaketitle

\section{Introduction}\label{intro}
The number of deaths and missing people due to natural disasters remains a serious problem in many countries. According to a report by the Centre for Research on the Epidemiology of Disasters\cite{CRED2016}, the average number of deaths and missing people due to natural disasters occurring worldwide, such as earthquakes, hurricanes, forest fires, and floods, from 2006 to 2015 was approximately 70,000. 
To reduce this number, a solution is to increase the number of rescue teams. The report by the Japan Ministry of Defense after the Great East Japan Earthquake suggests that it is necessary to secure manpower through guidelines regarding the concentration of units in the immediate aftermath of a disaster. However, a huge budget to secure manpower and the risk of secondary damage in disaster-hit areas are problems to be solved\cite{disaster2011}. 

Micro or small unmanned aerial vehicles (UAVs), also known as drones, are expected to solve the above problems in areas where humans and ground vehicles cannot easily enter, such as areas damaged by disaster. Technological advances in recent years have led to the emergence of smaller and cheaper UAVs, which can provide functions such as transporting relief supplies, collecting data by using onboard sensors, and forming ad hoc wireless mesh network infrastructures in such isolated areas \cite{Andre2014,Erdelj2016,Felice2014}. 
Collecting image data is especially important because it is applicable to many use cases such as search and rescue missions and fire detection and surveillance. Since there are time constraints in such situations, UAVs need to collect sensor data as soon as possible. 
During the Great East Japan Earthquake, the number of deaths and missing people dramatically increased as time passed\cite{japan2011}. 
Surveillance using multiple UAVs has been receiving increasing attention for reasons such as increasing system reliability, robustness, and efficiency\cite{Lanillos2014,Maza2007,Meng2014,chang2016,Mirzaei2011}.

From a user-centric viewpoint, however, the time requirement in such surveillance scenarios should be strict. Previous studies assumed that a user can obtain necessary information as soon as a UAV acquires image data. However, neither the processing time of image data or data-transfer time were taken into consideration. In actual situations, it takes a long time to analyze images for target recognition due to the limited computational resources of small UAVs. In addition, the data-transfer time can increase in disaster-hit areas due to damage to communication infrastructures.

Therefore, we propose a scheduling method of multi-UAV search systems that takes into account the processing time of image data and data-transfer time. We present a utility-based problem formulation that ensures the freshness of each piece of obtained information while obtaining as many pieces of information as possible for a certain period. We show that the proposed scheduling method maximizes user utility, which is calculated from the efficiency of obtaining results from analyzed data and the interval of obtaining the results, through basic performance evaluation. We also conducted a simulation using three evaluation metrics from a user-centric viewpoint to verify the effectiveness of the proposed scheduling method against [a benchmark a conventional scheduling method.

The remainder of this paper is organized as follows. In Section II, we discuss related work. In Section III, we give an overview of the multi-UAV search system we assumed for this study and the proposed scheduling method. In Section IV, we discuss the basic performance evaluation of our method in terms of user utility followed by a simulation using three evaluation metrics from a user-centric viewpoint in Section V. Finally, we conclude the paper in Section VI. Note this paper is an extended version of a paper the authors presented at IEEE GCCE 2018 \cite{GCCE2018}.

\section{Related work}
As described in Section \ref{app}, UAVs are used for data collection using onboard sensors in disaster areas, which is what we assumed for this study. In Section \ref{cover}, we discuss multi-UAV cooperation for area coverage; UAVs in the multi-UAV search system we assumed for this study also work cooperatively to cover a sensing region. In Section \ref{compute}, discuss the computing issue with UAVs, which was an important factor in our study, though we assumed only cooperative computing with an edge server; inter-UAV cooperation for computing is out of the scope from this paper.

\subsection{UAV Applications in disaster areas}\label{app}
Transporting relief supplies by using UAVs is very important since there is a possibility that humans and ground vehicles may not be able to easily enter disaster areas.
Bamburry mentioned the ability of a UAV to deliver medical products to remote and hard-to-reach areas\cite{Bamburry2015}.
For example, in the devastating 2010 earthquake in Haiti, a UAV delivery system was used to deliver medicine to camps set up after the disaster\cite{May2015}.

UAVs can also collect data by using onboard sensors. In the study by Wada et al. \cite{Wada2015}, Each UAV was provided with mobile optical sensors and image transmission modules they developed. 
An optical sensor, which is a combination of an infrared sensor and visible-light sensor, enables data collection even at night or in smoky disaster areas. 
After launch, a UAV executes auto flight by recognizing its positions and obtains the necessary video/image information. 
The UAV transmits the information to the server and shares it with users via the Internet.

UAVs also often work for forming an ad hoc wireless mesh network infrastructure, which is called a Flying Ad Hoc Network (FANET)\cite{Bekmezci2013}. In 2016, S\'anchez et al. aimed to provide connectivity for rescuers and disaster victims using UAVs\cite{Garcia2016}. They proposed Jaccard-based movement rules to define the best positions of UAVs for providing the best communication service to victims in an urban disaster scenario. They also compared several local search computational intelligence algorithms, such as simulated annealing, hill climbing, and random walk, for determining the best tactical UAV movements.

\subsection{Multi-UAV cooperation for area coverage}\label{cover}
Maza et al. conducted a pioneering study on cooperatively searching a given area to detect objects of interest by using UAVs\cite{Maza2007}. They first determined the relative capabilities of each UAV based on factors such as flight speed, altitude required for the mission, sensitivity to wind conditions, and sensing width. They then divided the entire area by using a divide-and-conquer approach, taking into account the UAV's relative capabilities and initial locations. Finally, they set the waypoints of each UAV so that the number of turns needed along a zigzag pattern is minimized.

Zhao et al. in 2016 tackled the challenging problem of not only searching the target area for a lost target but also tracking the target\cite{chang2016}. In the tracking stage, each UAV maintains the desired distance with the target, coordinating the angular separation between neighboring UAVs to the same angle. If there is a shelter between the UAV and target, the target state is predicted from the target model with the former target information. In the searching stage, multiple UAVs divide the search region equally, which is determined by the target-loss duration and speed, then search for the target by using the method of shrinking annulus. Switching tactics between the tracking and searching stages were also proposed.

In 2017, Hayat et al. proposed a multi-objective optimization algorithm to search for and plan paths for UAVs\cite{Hayat 2017}. UAVs search for a target cooperatively and soon after a UAV detects the target; the other UAVs takes positions for relay chain formation between the detecting UAV and base station. The algorithm minimizes the mission-completion time, which includes the time to find the target and time to setup a communication path. They also compared three similar UAV search strategies but have different path planning in terms of the mission-completion time.

\subsection{Multi-UAV cooperation for computing}\label{compute}
UAV Applications in disaster areas require UAVs to deal with intensive computation tasks such as image/video processing, pattern recognition and feature extraction. 
Computation offloading is very important since computational power of a single UAV is limited.

\subsubsection{Inter-UAV cooperation}
Ouahouah et al. in 2017 proposed the use of an offloading mechanism among UAVs equipped with internet-of-thing (IoT) devices\cite{Ouahouah2017}. 
Each IoT task is partitioned into a set of sub-tasks that can be executed simultaneously among a cluster of UAVs. The sub-tasks are assigned to UAVs based on their power supply, resources in terms of memory and CPU computation, and their on-board IoT devices. 
Two solutions were proposed for computation offloading, i.e., energy-aware optimal task offloading and delay-aware optimal task offloading. 
The former maximizes the UAVs lifetime by selecting the UAVs with higher power supply. The latter reduces the response time by favoring the selection of UAVs with more resource capacities.

In 2018, Valentino et al. proposed an opportunistic and adaptive computational offloading scheme between UAV clusters\cite{Valentino2018}.
A cluster head will broadcast a `hello' message indicating their presence and available resources and then a local cluster sends an offloading request to a desired cluster head.
The local cluster determines if it is better to do the task alone or to offload, by estimating response time for doing the computational offloading and processing the given task through computing power, task size, bandwidth, and data rate of the wireless network.

\subsubsection{Edge computing}
Edge computing has been proposed as an effective mean of supplementing computational resources for UAVs\cite{Motlagh2017,Messous2017}.

Motlagh et al. in 2017 demonstrated how UAVs can be used for crowd surveillance based on face recognition. Due to the computational overhead required by such a use case and given the limited power supply of UAVs, they carried out the offloading of video-data processing to a mobile edge computing node. The results clearly indicated the benefits of computation offloading compared to the local processing of video data onboard UAVs in saving energy and quickly detecting and recognizing suspicious individuals in a crowd.

Messous et al. in 2017 tackled the computation offloading problem with three different devices: UAV, base station, and edge server, which carry out heavy computation tasks. They proved the existence of a Nash Equilibrium and designed an offloading algorithm that converges to the optimal point. Their cost function was defined as a combination of two performance metrics: energy and delay. They finally achieved better utility value using the offloading algorithm compared to computing on an edge server, base station, or drone.

\section{Proposed method}\label{method}

\subsection{Multi-UAV search system overview}\label{sys}
\subsubsection{System model}\label{sysmo}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.0cm]{fig/system_illustration.pdf}
\caption{Diagram of multi-UAV search system }
\label{model}
\end{center}
\end{figure}


Figure \ref{model} depicts the multi-UAV search system model we assumed for this study. The system consists of a user device (UD), multiple UAVs, and an edge server (ES), the roles of which are described as follows. 
%
The UD is the central operating entity in the system and operates all the UAVs and ES; the UD determines flying routes and timing of UAVs and assigns workloads of computing sensor data to the UAVs and ES.
%
The UD also works to forward sensor data received from UAVs to the ES and to obtain computational results from both UAVs and the ES.

Each UAV is operated by the UD and performs the following actions autonomously in a distributed manner.
%直すとおかしい部分
%
(i) Flying between the initial position, at which the UAV can communicate directly with the UD, and the sensing region assigned to the UAV.
(i\hspace{-.1em}i) Acquiring image data (still or moving images) of the sensing region assigned to the UAV.\\
(i\hspace{-.1em}i\hspace{-.1em}i) Staying at the initial position and performing the following actions in parallel: (a) analyzing some of the collected image data with the computational power of the UAV and (b) delegating the analysis of the rest of the data to the ES.
(i\hspace{-.1em}v) Reporting results obtained from  from the image-data analysis to the UD soon after it has been completed.
%
Note that we assume that UAVs cannot perform any analysis while flying; computational resources of UAVs are fully used for flight control and image acquiring during the flight. Each UAV repeats all the actions (i) to (i\hspace{-.1em}v). We call one cycle of actions (i) to (i\hspace{-.1em}v) of a UAV one round. %
The ES is placed closely to the UD to perform the analysis of some of the image data received from the UAVs.
%
Like UAVs do, soon after the ES has completed the analysis, it reports the results to the UD.

\subsubsection{System flow}\label{flow}
In our system, the schedules of flying, acquiring, and analyzing of UAVs are determined through the following steps:
%
\begin{description}
\item[(1)] Check if there is one or more UAVs the schedules of which have not been determined yet. If yes, go to step (2). Otherwise repeat step(1).
\item[(2)] Pick one of the unscheduled UAVs and label it as UAV $i (i=1, 2, 3, \cdots)$, if step (1) is yes.
\item[(3)] Refer to the information about the schedules of UAVs $i-1$, $i-2$, $i-3$, $\cdots$, which were scheduled before UAV $i$.
\item[(4)] Determine the schedule of UAV $i$ by using a scheduling method, which is described later.
\item[(5a)] Increment $i$ to $i+1$. Go back to step (1).
\item[(5b)] UAV $i$ starts its operation based on the determined schedule and will be added to the list of unscheduled UAVs after completing all the actions\hspace{-0.5mm} (i) to (i\hspace{-.1em}v) mentioned in Section \ref{sysmo}.
\end{description}
%
Note that (5a) and (5b) are executed in parallel.
%
At step (4), the scheduling method requires some time for calculating the schedule of UAV $i$.
%
The calculating time depends on the complexity of the scheduling method.
%
Therefore, the complexity of the scheduling method should not be complicated.
%
However, during the second or later round of the scheduling for a UAV, the calculation can be done while the UAV is performing step (5b) because all the previous schedules before the UAV have been determined already and the information of all the previous schedules are available.
%
%
When the ES receives a computational task from a UAV via the UD, the ES places it into the waiting queue. 
The ES processes those computational tasks in first-in first-out (FIFO) manner and reports the results to the UD immediately after finishing each computational task.

\subsection{Scheduling method}\label{math}
For simplifying our theoretical discussion, we first assume the system model shown in Figure \ref{model1.5}, in which sensing sections are placed on a one-dimensional line and their sizes are identical.
%
Sensing sections are assigned to UAVs from the one closest to the initial position and only an image is acquired at each sensing section.
%
These assumptions allow us to simply consider the sensing range of each UAV as the number of images acquired by them.
%
We also assume that, if the computing resource of the ES or the communication channel of the UD is still used by previously scheduled UAVs (UAVs $1, 2, \cdots, i-1$), UAV $i$ has to wait in FIFO manner until their operations are completed.
%
This also means that the operation of UAV $i$ does not affect those of the previous UAVs (UAVs $1, 2, \cdots, i-1$).

\begin{figure}[t]
\begin{center}
\includegraphics[width=7.0cm]{fig/onedimention.pdf}
\caption{System model for problem formulation}
\label{model1.5}
\end{center}
\end{figure}

\subsubsection{Utility}\label{to}
This section presents the mathematical formula of the utility function of UAV $i$, $U_i$, which is given as

\begin{align}
U_i = \frac{\eta^i}{{\Delta{t}}^i}, \label{ut}
\end{align}
where $\eta^i$ means the efficiency of obtaining results from analyzed data and ${\Delta{t}}^i$ is the interval of obtaining the results.
%
They are called acquisition efficiency and acquisition interval, respectively, and defined as

\begin{align}
\eta^i&=\frac{N^i}{{t_{\mathrm{fin}}^i}-{t_{\mathrm{start}}^i}} \label{f1}\\
{\Delta{t}}^i &= {t_{\mathrm{fin}}^i}-t_{\mathrm{fin}}^{i-1}~~~~(t_ {\mathrm{fin}}^0=0, {t_{\mathrm{fin}}^i}\geq{t_{\mathrm{fin}}^{i-1}}), \label{f2}
\end{align}
where $N^i$ means the number of images acquired by UAV $i$, $t_{\mathrm{start}}^i$ is the flight start time of UAV $i$, and $t_{\mathrm{fin}}^i$ is the time when processing $N^i$ images is finished. The utility function defined by (\ref{ut}) suggests that, as the acquisition efficiency and interval become higher and shorter, the system works better for users. The reason it is reasonable is because, in surveillance scenarios, users expect to obtain as many pieces of information as possible during a certain period, while more updated information would be more valuable to them.

\subsubsection{Problem formulation}

\begin{table}[t]
\centering
\caption{Definition of notation}
  \begin{tabular}{|c|l|} \hline
 & Description
 \\ \hline
 $N^i$ & No. of images acquired by UAV $i$ \\ \hline
 $N_u^i$ & No. of images processed by UAV $i$ \\ \hline
 $N_e^i$ & No. of images delegated from UAV $i$ to ES   \\ \hline
 \shortstack[l]{$D$\\ ~}& \shortstack[l]{Distance between initial position and \\left-end of sensing block} \\ \hline
 $d$ & Size of each sensing section     \\ \hline
  $v^{i}$ & Flying speed of UAV $i$    \\ \hline
 $T_g$ & Image-acquisition time per sensing section \\ \hline
  $T_{u,d}^{i}(N^i,N_u^i)$ & Transmission-waiting time from UAV $i$ to UD  \\ \hline
 \shortstack[l]{$T_{d,e}^{i}(N^i,N_u^i)$\\ ~} & \shortstack[l]{Transmission-waiting time of UAV $i$'s data\\from UD to ES}  \\ \hline
 $T_e^{i}(N^i,N_u^i)$ & Processing-waiting time at ES  \\ \hline
 \shortstack[l]{$\mu_{u,d}$\\ ~} & \shortstack[l]{Transmission speed from UAV $i$ to UD\\regarding no. of images per unit time} \\ \hline
 \shortstack[l]{$\mu_{d,e}$\\ ~} &  \shortstack[l]{Transmission speed from UD to ES\\regarding no. of images per unit time} \\ \hline
 \shortstack[l]{$P_u^i$\\ ~} &  \shortstack[l]{Processing speed of UAV $i$\\regarding no. of images per unit time} \\ \hline
 \shortstack[l]{$P_e$\\ ~} &   \shortstack[l]{Processing speed of ES\\regarding no. of images per unit time} \\ \hline
\end{tabular}
\label{para}
\end{table}

This section discusses the problem formulation of the proposed scheduling method.
%
Table \ref{para} lists the definition of the notation we use.
%
In this table, $N^i$, $N_u^i$, and $N_e^i$ are variables.
%
The problem formulation is described below by using these notations:

\begin{align}
\arg \max_{\hspace{-5mm}N^i,N_u^i} \quad&  U_i =\frac{\eta^{i}}{{\Delta{t}}^i}  = \frac{N^i / (t_{\mathrm{fin}}^i(N^i,N_u^i)-t_{\mathrm{start}}^i)}{t_{\mathrm{fin}}^i(N^i,N_u^i)-t_{\mathrm{fin}}^{i-1}}\label{eq1} \\
{\mathrm {s.t.}} \quad& {N_\mathrm {MIN}^i}\leq{N^i}, \label{eq2}
\end{align}
where $N_{MIN}^i$ means that UAV $i$ has to acquire at least $N_{MIN}^i$ images so as not to complete its actions earlier than the previous UAV, UAV $i-1$: ${t_{\mathrm{fin}}^i}\geq{t_{\mathrm{fin}}^{i-1}}$.
This formulation suggests that $N^i$ and $N_u^i$ must be determined so that the utility function, $U^i$, is maximized.

The $t_{\mathrm{fin}}^i$ in (\ref{eq1}) is represented as
\begin{align}
&t_{\mathrm{fin}}^i(N^i,N_u^i)=t_{\mathrm{start}}^i+\frac{2}{v^i}(D+\sum_{j=1}^{i-1}{N^{j}d})+\nonumber\\
&\hspace{-1mm}N^i({T_g+\frac{d}{v^i}})+\max(\frac{N_u^i}{P_u^i},T_{u,d}^{i}(N^i,N_u^i)+\nonumber\\
&\hspace{-1mm}\frac{N_e^i}{\mu_{u,d}}+T_{d,e}^{i}(N^i,N_u^i)+\hspace{-1mm}\frac{N_e^i}{\mu_{d,e}}+T_{e}^{i}(N^i,N_u^i)+\hspace{-1mm}\frac{N_e^i}{P_e}). \label{eq_fin}
\end{align}

Eliminating $N_e^i$ from (\ref{eq_fin}) using $N^i=N_u^i+N_e^i$, $t_{\mathrm{fin}}^i(N^i,N_u^i)$ becomes a function of two variables, $N^i$ and $N_u^i$. According to (\ref{eq_fin}), $t_{\mathrm{fin}}^i-t_{\mathrm{start}}^i$ is equal to the sum of flight time, transmission time, and processing time of UAV $i$. The second and third terms on the right side of (\ref{eq_fin}) represent the flight time outside the sensing range of UAV $i$ and the sum of the image-acquisition and flight times within the sensing range assigned to UAV $i$, respectively. The max function of the fourth term on the right side of (\ref{eq_fin}) is the processing time of $N^i$ images, which is equal to the longer image-processing time at the UAV $i$ or the total time required for image transmission from UAV $i$ to the ES and the image processing at the ES. The $T_{u,d}^{i}(N^i,N_u^i)$, $T_{d,e}^{i}(N^i,N_u^i)$, and $T_e^{i}(N^i,N_u^i)$ on the right side of (\ref{eq_fin}) are waiting times for UAV $i$. As we mentioned above, if previous UAVs (UAV1,UAV2,$\cdots$, UAV${i-1}$) are still using the communication channel of the UD or the computational resource of the ES, UAV $i$ has to wait for a certain time until all the transmission and processing tasks have been completed. That is, $t_{\mathrm{fin}}^{i-1}$, which is the time when processing $N^{i-1}$ images acquired by UAV $i-1$ is finished, is not affected by the operation of UAV $i$ and can be considered a constant value in the scheduling of UAV $i$. Since the size of output data obtained after processing at UAVs and the ES are quite small, we assumed that the transmission time of those output data is negligible.

The $N_{MIN}^i$ in (\ref{eq2}) is the specific value of $N^i$ that satisfies the following condition:
%
\begin{align}
\arg \min_{\hspace{-5mm}N^i,N_u^i} \quad& {t_{\mathrm{fin}}^i(N^i,N_u^i)}\label{eq_min1}\\
s.t. \quad& {t_{\mathrm{fin}}^i(N^i,N_u^i)}\geq{t_{\mathrm{fin}}^{i-1}}({N_u^i}\in \mathbb{N}\mid 0\leq{N_u^i}\leq{N^i}). \label{eq_min2}
\end{align}
%
Suppose that ${N_u^i}$ is determined to minimize $t_{\mathrm{fin}}^i(N^i,N_u^i)$ for a given $N^i$. For such ${N_u^i}$, $N_{MIN}^i$ is the minimum integer among possible values of $N^i$ that satisfy (\ref{eq_min2}). By setting $N_{MIN}^i$ as long as ${N_u^i}$ is chosen to satisfy $0\leq{N_u^i}\leq{N^i}$, the optimal $N^i$ in (\ref{eq1}) can be determined among the possible values of $N^i$ that satisfy $U^i$(=$\frac{\eta^{i}}{{\Delta{t}}^i}) > 0$.

The solution for (\ref{eq1}) and (\ref{eq2}) is mentioned in detail in Appendix \ref{ape}.

\subsection{Requirements of scheduling for multi-UAV search system} \label{feature}
From a user-centric viewpoint, the scheduling of multi-UAV search systems should satisfy the four requirements described below.
\begin{itemize}
\item Robustness against the increase or decrease in number of UAVs: The number of UAVs may increase due to adding new UAVs to the existing UAV group or decrease due to UAV breakdown. If there are new UAVs, they are added to the group of the unscheduled UAVs in step (1) of the system flow mentioned in Section \ref{flow}. If some UAVs break down on the way, the UAVs that were planned to start operations afterwards are rescheduled. These UAVs are added to the group of the unscheduled UAVs in step (1) of the system flow.
%
\item Applicability for the heterogeneity of UAVs: 
There are individual differences in the flying speed and the processing speed of each UAV. 
In our proposed scheduling method, such individual differences is considered in (\ref{eq_fin}).
%
\item Applicability for various processing capacities of UAVs and the ES: The computational performance of each UAV and the ES greatly depends on the machine capability. With the proposed method, it is possible to efficiently use the computing capacity of each UAV and the ES since $t_{\mathrm{fin}}^i(N^i,N_u^i)$ in (\ref{eq_fin}) is defined considering machine performance.
%
\item Feasibility for extension to various geographical areas: There are many types of geographical areas in practical situations. As we discuss shortly in Section \ref{twodi}, by extending the one-dimensional model shown in Fig. \ref{model1.5}, our proposed scheduling method is applicable for two-dimensional models. It is obvious that extension to three-dimensional models can also be considered, though the details are not presented in this paper
\end{itemize}

\section{Basic performance evaluation}\label{eva}
We verified that the proposed scheduling method maximizes user utility through a basic performance evaluation.
\subsection{Simulation scenario}
We considered a surveillance scenario in which a rescue team uses the multi-UAV system illustrated in Figure \ref{model} to find missing people in an area where humans and ground vehicles cannot easily enter. We assumed the simple model illustrated in Figure \ref{model1.5}, in which sensing sections are placed on a one-dimensional line and their sizes are identical, to present the problem formulation. Our simulation adopted the proposed scheduling method described in Section \ref{math} and performed every step of the system flow described in Section \ref{flow}. We compared the proposed method with a conventional scheduling method: fixed method, which simply assigns a fixed number of sensing sections to each UAV uniformly \cite{chang2016}. In the fixed method, $N_u^i$ is determined so that $t_{\mathrm{fin}}^i$ is minimized. In our basic evaluation, we assumed that the user cumulatively obtains $U_i$, which is defined by (\ref{ut}), every time UAV $i$ finishes one round at $t_{\mathrm{fin}}^i$. Then, we observed how the cumulative summation of $U_i$ increases over time after the first UAV has started flying.

\subsection{Simulation parameters}
The parameters used in our simulation are listed in Table \ref{para_val}. Considering the realistic specifications of a recently commercialized UAV \cite{bebop2}, we set the flying speed of UAVs to 15 m/s. The image size was set to 100 kbytes, which corresponds to that in the dataset called PASCAL VOC 2007 used in a previous study \cite{Ren2015}. The times required for processing one image at UAVs and the ES were set corresponding to the time required for object recognition using GPUs and CPUs \cite{Ren2015}, respectively. As described in Section \ref{feature}, we need to consider the heterogeneity of UAVs from a user-centric viewpoint. Therefore, the flying speed of and number of images processed by UAVs were given by the normal distributions where the mean and deviation were $\mu$ and $\sigma$. We set $\sigma$ = 0.1$\mu$ and the upper and lower limits to $\mu+2\sigma$ and $\mu-2\sigma$, respectively. The transmission rates of the communication channel from the UAVs to the UD and from the UD to the ES were set 100 Mbps, which is similar to the effective throughput of IEEE802.11n \cite{Li2013}.

\subsection{Results}
Figures \ref{utility} (a) and \ref{utility} (b) plot the cumulative sum of utilities against elapsed time after start time with $D$=200 and $D$=600, respectively. We examined the fixed method with $N^i$ = 1, 10, 40, and 80. As we see in the figures, the cumulative sum of utilities with both methods remained almost constant then increased as time passed. The cumulative sum of utilities with the proposed method was the largest at any elapsed time, which suggests that the proposed method performs better than the fixed method in terms of the cumulative sum of utilities.
\begin{figure*}[t]
\begin{center}
\includegraphics[width=16.0cm]{fig/totalutility.png}
\caption{Cumulative sum of utilities}
\label{utility}
\end{center}
\end{figure*}

\begin{table}
  \begin{center}
    \caption{Simulation parameters}
    \label{para_val}
    \begin{tabular}{ll}
     \hline
Parameters & value \\ \hline
No. of UAVs ($U$) & 5\\
Average flying speed of UAVs & 15 m/s \\
\shortstack[l]{Distance from initial position \\to left-end of sensing block ($D$)} & \shortstack[l]{200,600m\\~}  \\ 
Size of each sensing section ($d$) & 5 m  \\ 
Time required for acquiring one image & 2 s \\ 
Transmission rate of communication channel & 100 Mbps \\ 
Size of image  &  100 kbytes \\ 
\shortstack[l]{Average processing speed of UAVs \\regarding no. of images per unit time ($\overline{P_u}$)} & \shortstack[l]{$\frac{1}{1.83}$\\~} \\ 
\shortstack[l]{Processing speed of ES regarding no. of images \\per unit time ($P_e$)} & \shortstack[l]{$\frac{1}{0.198}$\\~} \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\section{Evaluation from user-centic viewpoint}
We discuss the three evaluation metrics we used to evaluate our proposed scheduling method from a user-centric viewpoint.

\subsection{Extension to two-dimensional model}\label{twodi}
Before introducing the evaluation metrics, we introduce the two-dimensional model we used for the evaluation.
The following two assumptions make our proposed scheduling method described in Section \ref{math} easily applicable for two-dimensional models shown in Figure \ref{twodimention}.

\begin{description}

\item[(1)]  Assuming a fan-shaped sensing region, split the region so that each sensing-section range is constant
\item[(2)] Each UAV executes sensing on a zigzag in order from the area closest to the center, such as in a previous study \cite{Maza2007}
\end{description}

In Figure \ref{twodimention}, the vertical width of each partition is $d$ and the central angle of the sensing region is $\theta$ [rad].
Then, the distances between each neighboring section is $d$ for the direction opposite to the center of the region, while the ones between each neighboring section for the circumference is $\frac{1}{2}d\theta$.
Therefore, when $\theta=2$ [rad], all the distances between neighboring sections equal $d$, as shown in Figure \ref{model1.5}. Then, since the two-dimensional model in Figure \ref{model1.5} can be used in the  same manner as a one-dimensional model, the proposed scheduling method is easily applicable.
\begin{figure}[t]
\begin{center}
\includegraphics[width= 7cm]{fig/twodim.png}
\caption{Sensing region of two-dimensional model}
\label{twodimention}
\end{center}
\end{figure}

\subsection{Evaluation metrics}\label{compare}
We used the following three evaluation metrics from a user-centric viewpoint.

\paragraph*{Two types of elapsed times}
The first metric is divided into two types. 
The first type is `elapsed time from start time' for each image, which is the elapsed time since the first UAV starts flying until each image result is obtained by the UD. 
This metric is important for a rescue team because they need to know about each sensing section as soon as possible to determine whether there are missing people. 
The second one is `elapsed time after acquired' for each image, which is the elapsed time since an image is acquired at the corresponding sensing section until the image result is obtained by the UD. This metric is also valuable for a rescue team because it indicates the freshness of the information about each sensing section; the less the information is updated, the less reliable it is when searching for missing people.

\paragraph*{No. of images satisfying time requirements}
The second metric is number of images satisfying the time requirements: the number of images that satisfy shorter elapsed time after acquired than a predetermined threshold at a certain time. This metric is important for a rescue team because they need to obtain fresh information while obtaining as many pieces of information as possible for a certain period.

\paragraph*{Information value obtained by user}
The third metric is the cumulative summation of how valuable the information obtained by the user each time is, i.e. information value. In a previous paper \cite{NOMURA2001}, the value function of the obtained image $j$ at elapsed time from start time $t$ was given as
\begin{align}
V_j=2^{-\frac{t}{T_{half}}}, \label{eq_value}
\end{align}
where $T_{half}$ means the half-life of the value, which is a parameter set according to the time requirements in a disaster situation. The user obtains $V_j$ when obtaining the result from processed image $j$. This metric allows us to measure how much valuable information the user obtained before the rescue team starts their rescue. 

\subsection{Results}

\begin{figure}[t]
\begin{center}
\includegraphics[width=8cm]{fig/elapsedtime.png}
\caption{Two types of elapsed times}
\label{elapsed}
\end{center}
\end{figure}

\begin{figure*}[t]
\begin{center}
\includegraphics[width=18.0cm]{fig/noimage.png}
\caption{No. of images that had shorter elapsed time after acquired than 120 [s] at 600 [s] after start time}
\label{totalnumber}
\end{center}
\end{figure*}

\begin{figure*}[t]
\begin{center}
\includegraphics[width=18.0cm]{fig/totalvalue.png}
\caption{Cumulative sum of values}
\label{totalvalue}
\end{center}
\end{figure*}

Figure \ref{elapsed} (a) plots the elapsed time from the start time for acquired images against each area id. 
In Fig. \ref{elapsed} (a), as the area id increased, the elapsed time from start time monotonically increased in both methods. With the fixed method, as the area id increased, $N^i$ giving the shortest elapsed time from the start time became larger for each area id. 
The performance of the proposed method was between those of the fixed method with $N^i=10$ and $N^i=40$. 
On the other hand, Figure \ref{elapsed} (b) plots the elapsed time after acquired for each image. 
The elapsed time after acquired decreased with a regular pattern with both methods. However, with the fixed method, as $N^i$ was set smaller, the elapsed time after acquired became shorter. The performance of the proposed method was between those of the fixed method with $N^i=10$ and $N^i=40$. With the fixed method, $N^i=10$ and $N^i=40$ were reasonable; the elapsed times from start time of them were between the best and the third best, while their elapsed times after acquired were much shorter than that of $N^i=80$. The performance of the proposed method was between the fixed method with $N^i=10$ and $N^i=40$ in both types of elapsed times, which suggests that it enables us to automatically achieve a reasonable $N^i$.

Figures \ref{totalnumber} (a), \ref{totalnumber} (b), and \ref{totalnumber} (c) plot the numbers of images that satisfied shorter elapsed time after acquired than 120 s at 600 s against the processing speed at the ES regarding the no. of images per unit time, number of UAVs, and distance from the initial position to the closest sensing block (area id = 1), respectively. The plots were obtained by averaging the results obtained from three trials. On the left side of Figure \ref{totalnumber} (a), the processing speed at the ES was sufficiently lower than the average processing speed at the UAVs, which corresponds to the case in which processing is performed mainly at UAVs not the ES. On the right side of Figure \ref{totalnumber} (a), the average processing speed at the UAVs was sufficiently lower than the processing speed at the ES, which corresponds to the case in which processing is performed mainly at the ES not at the UAVs. As shown in Figures \ref{totalnumber} (a) and (b), the proposed method performed at a sufficient level for different values of $\frac{P_e}{\overline{P_u}}$ and $U$, while different $N^i$ was the best for different parameters with the fixed method. As shown in Figure \ref{totalnumber} (c), the proposed method continued working at a sufficient level for different $D$, while the no. of images with the fixed method monotonically decreased as $D$ was set larger.

Figure \ref{totalvalue} plots the cumulative sum of values against the elapsed time from start time. The half-life in Figures \ref{totalvalue}(a), \ref{totalvalue}(b), and \ref{totalvalue}(c) was 30, 60, and 120 s, respectively. As shown in these figures, the cumulative sum of values monotonically increased with both methods. The proposed method performed at a sufficient level for a wide variety of half-lives, while different $N^i$ was the best for different half-lives with the fixed method.

From the results in Figures \ref{totalnumber} and \ref{totalvalue}, since the proposed method performed at a sufficient level without setting a reasonable $N^i$ according to the parameter, unlike the fixed method, we can conclude that the proposed method performed best in this evaluation scenario.


\section{Conclusion}
We proposed a scheduling method of multi-UAV search systems that, from a user-centric viewpoint, takes into account the processing time of the acquired image data and data-transfer time in areas where humans and ground vehicles cannot enter such as areas damaged by disaster. We first discussed a multi-UAV search system, which consists of a user device, multiple UAVs, and an edge server, and explained the system's flow. We then presented a utility-based problem formulation that ensures the freshness of each obtained piece of information while obtaining as many pieces of information as possible for a certain period. We presented the results of a basic performance evaluation to verify that in terms of cumulative sum of utilities, the proposed method performed better than the fixed method, which simply uniformly assigns a fixed number of sensing sections to each UAV. In addition, a simulation using three evaluation metrics showed that the proposed method performs at a sufficient level from a user-centric viewpoint. Future work includes practical implementation.

\appendices
\section{Solution of the problem formulation}\label{ape}
It takes long time to solve (4) and (5) due to their computational complexities, and the calculation for scheduling may incur non-negligible overhead in the system; UAVs have to wait to start flying until their schedules have been determined. Therefore, to simplify the calculations of (\ref{eq1}) and (\ref{eq2}), it is first assumed with our scheduling method that all waiting times for UAV $i$ are equal to zero and approximated solution, $N_{th}^i$, is obtained. Then, by searching locally around $N_{th}^i$, our scheduling method takes into account all waiting times in (\ref{eq1}) and (\ref{eq2}) and finds the local optimal solution $N_{l}^i$. The following section explains the process of determining $N_{th}^i$. First, we set all the waiting times to zero. Then, we replace the second and fourth terms in (\ref{eq_fin}) with $2F$ and $M$, respectively. Then, by substituting ${t_{\mathrm{fin}}^i}$ in (\ref{eq_fin}) with (\ref{ut}), we obtain $\frac{\eta^i}{{\Delta{t}}^i}$ as below:
%
\begin{align}
\frac{\eta^{i}}{{\Delta{t}}^i}
=&\frac{N^i}{N^i({T_g}+\frac{d}{v^i})+2F+M}\times\nonumber\\
&\frac{1}{N^i({T_g}+\frac{d}{v^i})+2F+M+t_{\mathrm{start}}^i-t_{\mathrm{fin}}^{i-1}}\label{eq4}
\end{align}
%
where, by regarding $N^i$ as a constant, only $M$ is a variable and $\frac{\eta^{i}}{{\Delta{t}}^i}$ varies depending on $N_u^i$ and $N_e^i$. Since $\frac{\eta^{i}}{{\Delta{t}}^i}$ is always positive, $M$ takes the minimum value when $\frac{\eta^{i}}{{\Delta{t}}^i}$ takes the maximum value. Although $N^i$, $N_u^i$, and $N_e^i$ are integers, we consider them as real numbers. Considering $N^i=N_u^i + N_e^i$, on the assumption that $\frac{N_u^i}{P_u^i}$ equals $\frac{N_e^i}{\mu_{u,d}}+\frac{N_e^i}{\mu_{d,e}}+\frac{N_e^i}{P_e}$, we can obtain $N_u^i$ and $N_e^i$ that satisfy $0\leq{N_u^i}$ and ${N_e^i}\leq{N^i}$ as follows:

\begin{align}
N_u^i=\frac{P_u^i(\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e})}{\mu_{u,d}\mu_{d,e}P_e+P_u^i(\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e})}N^i\label{eq5}\\
N_e^i=\frac{\mu_{u,d}\mu_{d,e}P_e}{\mu_{u,d}\mu_{d,e}P_e+P_u^i(\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e})}N^i\label{eq6}
\end{align}
%
When $M$ takes the minimum value, $\frac{N_u^i}{P_u^i}$ is theoretically equal to $\frac{N_e^i}{\mu_{u,d}}+\frac{N_e^i}{\mu_{d,e}}+\frac{N_e^i}{P_e}$, while $N_u^i$ and $N_e^i$ become (\ref{eq5}) and (\ref{eq6}), respectively. As $N^i$ becomes larger, $\frac{N_u^i}{P_u^i}$ becomes closer to $\frac{N_e^i}{\mu_{u,d}}+\frac{N_e^i}{\mu_{d,e}}+\frac{N_e^i}{P_e}$. Thus, $\frac{N_u^i}{P_u^i}=\frac{N_e^i}{\mu_{u,d}}+\frac{N_e^i}{\mu_{d,e}}+\frac{N_e^i}{P_e}$ is established.\\ As a result, $\frac{\eta^{i}}{{\Delta{t}}^i}$ in (\ref{eq4}) is given as

\begin{align}
&\hspace{-0.2cm}\frac{N^i}{R^2{(N^i)}^2+(4F+t_{\mathrm{start}}^i-t_{\mathrm{fin}}^{i-1})R{N^i}+2F(2F+t_{\mathrm{start}}^i\hspace{-1mm}-t_{\mathrm{fin}}^{i-1})}\hspace{1cm}\label{eq_ec}\\
&\hspace{-0.6cm}\biggl(R=T_g+\frac{d}{v^i}+\frac{\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e}}{\mu_{u,d}\mu_{d,e}P_e+P_u^i(\mu_{d,e}P_e+\mu_{u,d}P_e+\mu_{u,d}\mu_{d,e})}\biggr)\nonumber
\end{align}
%
To sketch (\ref{eq_ec}), by differentiating it by $N^i$, we obtain:
%
\begin{align}
\hspace{-4mm} \frac{-{R^2{(N^i)}^2}+2F(2F+t_{\mathrm{start}}^i\hspace{-1mm}-t_{\mathrm{fin}}^{i-1})}{\{R^2{(N^i)}^2+(4F+t_{\mathrm{start}}^i\hspace{-1mm}-t_{\mathrm{fin}}^{i-1})R{N^i}+2F(2F+t_{\mathrm{start}}^i\hspace{-1mm}-t_{\mathrm{fin}}^{i-1})\}^2}
\end{align}
%
When $t_{\mathrm{start}}^i \leq{t_{\mathrm{fin}}^{i-1}-2F}$, (\ref{eq_ec}) decreases monotonically as $N^i$ increases and takes the maximum value when $N_{th}^i$ is $N_{MIN}^i$.
%
When $t_{\mathrm{start}}^i >{t_{\mathrm{fin}}^{i-1}-2F}$, $\frac{\eta^{i}}{{\Delta{t}}^i}$ is a convex function taking the maximum when $N^i$ is $\frac{\sqrt{2F(2F+t_{\mathrm{start}}^i-t_{\mathrm{fin}}^{i-1})}}{R}$.
%
Note that $N^i$ is chosen so that the denominator of (\ref{eq_ec}) does not become zero.
%
Through the above procedure, we can obtain $N_{th}^i$ as follows:
%
\begin{align}
 \hspace{-1.5mm} N_{th}^i= \begin{cases}
    \frac{\sqrt{2F(2F+t_{\mathrm{start}}^i-t_{\mathrm{fin}}^{i-1})}}{R} & ({N_{MIN}^i}\leq{\frac{\sqrt{2F(2F+t_{\mathrm{start}}^i-t_{\mathrm{fin}}^{i-1})}}{R}}) \\
    N_{MIN}^i& (\frac{\sqrt{2F(2F+t_{\mathrm{start}}^i-t_{\mathrm{fin}}^{i-1})}}{R}<{N_{MIN}^i})
  \end{cases}
\end{align}

In finding out the local optimal solution, $N_{l}^i$, the range of local searching in the proposed scheduling method was set enough wide so that it can ensure that the local optimal solution equals to the true optimal solution.
%
In addition, we assumed that the consumed time for finding out the local optimal solution is negligible; since the complexity of the scheduling algorithm is quite simple, the calculation can be finished in advance while the UAV is flying in the previous round.

In determining the local optimal solution $N_{l}^i$, the range of local searching with the proposed scheduling method was set wide enough to ensure that $N_{l}^i$ equals the true optimal solution. 
We also assumed that the time required for determining $N_{l}^i$ is negligible since the complexity of the scheduling algorithm is quite simple, the calculation can finish in the previous round before the UAV starts flying.

\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\begin{thebibliography}{1}
\bibitem{CRED2016}D. Guha-Sapir, P. Hoyois, P. Wallemacq and R. Below,``Annual Disaster Statistical Review 2016,"\emph{Centre for Research on
the Epidemiology of Disasters},2016 
\bibitem{disaster2011} Japan Ministry of Defense, ``Lessons from the Great East Japan Earthquake," \url{http://www.mod.go.jp/e/publ/w_paper/pdf/2012/30_Part3_Chapter1_Sec3.pdf}, 2012
\bibitem{Andre2014} T. Andre, K. Hummel, A. Schoellig, E. Yanmaz, M. Asadpour, C. Bettstetter, P. Grippa, H. Hellwagner, S. Sand and S. Zhang, ``User devicelication-driven design of aerial communication networks, " \emph{IEEE Commun. Mag.}, vol. 52, no. 5, pp. 129\UTF{2013}137, 2014
\bibitem{Erdelj2016} M. Erdelj, and N. Enrico, ``UAV-assisted disaster management: User devicelications and open issues, " \emph{2016 International Conference on Computing, Networking and Communications (ICNC)}, pp. 1\UTF{2013}5, 2016
\bibitem{Felice2014} M. Di Felice, A. Trotta, L. Bedogni, K. R. Chowdhury and L. Bononi, ``Self-organizing aerial mesh networks for emergency communication, " \emph{Personal, Indoor, and Mobile Radio Communication (PIMRC), IEEE 25th Annual International Symposium on}, pp. 1631\UTF{2013}1636, 2014
\bibitem{japan2011}A. Vervaeck and J. Daniell,``Japan Tohoku tsunami and earthquake : The death toll is climbing again!, " \url{https://earthquake-report.com/2011/08/04/japan-tsunami-following-up-the-aftermath-part-16-june/}, 2011
\bibitem{Lanillos2014} P. Lanillos, S. K. Gan, E. Besada-Portas, G. Pajares and S. Sukkarieh, ``Multi-UAV target search using decentralized gradient-based negotiation with expected observation,"\emph{Information Sciences}, vol. 282, pp. 92\UTF{2013}110, 2014.
\bibitem{Maza2007} I. Maza, A. Ollero, ``Multiple UAV cooperative searching operation
using polygon area decomposition and efficient coverage algorithms, "\emph{Distributed Autonomous Robotic Sys-tems}, pp. 221\UTF{2013}230, 2007.
\bibitem{Meng2014} W. Meng, Z. R. He, R. Teo, L. xie, ``Decentralized Search, Tasking and Tracking Using Multiple Fixed-Wing Miniature UAVs," \emph{11th IEEE International Conference on Control \& Automation (ICCA)}, pp. 1345\UTF{2013}1350, 2014 
\bibitem{chang2016} C. Zhao, M. Zhu and H. Liang, ``The Sustainable Tracking Strategy of Moving Target by Multi-UAVs in an Uncertain Environment, " \emph{2016 IEEE/CSAA International Conference on Aircraft Utility Systems (AUS)}, pp. 20\UTF{2013}25, 2016
\bibitem{Mirzaei2011} M. Mirzaei, F. Sharifi, B. W. Gordon, C. A. Rabbath and  Y. M.Zhang, ``Cooperative multi-vehicle search and coverage problem in uncertain environments, "\emph{in Proceedings of the 50th IEEE Conference on Decision and Control and European Control Conference (CDCECC)}, pp. 4140\UTF{2013}4145, 2011
%
\bibitem{GCCE2018}  K. Miyano, R. Shinkuma, E. Oki, and T. Sato, ``Utility Based Scheduling for Multi-UAV Search System in Disaster Scenarios,'' Proc. IEEE 7th Global Conference on Consumer Electronics (GCCE), Aug 2018.
\bibitem{Bamburry2015} D. Bamburry, ``Drones: Designed for product delivery," \emph{Design Management Review}, vol. 26, no. 1, pp. 40\UTF{2013}48, 2015
\bibitem{May2015} K. May,``Drones to deliver medicine and food? Drones for disaster relief? Why not?,"\url{https://ideas.ted.com/6-ways-drones-can-be-used-for-good/}, 2013
\bibitem{Wada2015} A. Wada, T. Yamashita, M. Maruyama, T. Arai, H. Adachi and H. Tsuji, ``A surveillance system using small unmanned aerial vehicle (UAV) related technologies,''\emph{NEC Technical Journal},vol.8, no. 1, pp. 68\UTF{2013}72, 2015
\bibitem{Bekmezci2013} I. Bekmezci, O. K. Sahingoz, and S. Temel, ``Flying Ad-Hoc Networks (FANETs): a survey,''\emph{Ad Hoc Networks}, vol. 11, no. 3, pp. 1254\UTF{2013}1270, 2013
\bibitem{Garcia2016} J S\'anchez-Garc\'ia, JM Garc\'ia-Campos, SL Toral, DG Reina and F Barrero, ``An intelligent strategy for tactical movements of UAVs in disaster scenarios,''\emph{
International Journal of Distributed Sensor Networks}, vol.12, no. 3, 2016
\bibitem{Hayat 2017} S. Hayat, E. Yanmaz, T. X. Brown, and C. Bettstetter,``Multi-Objective UAV Path Planning for Search and Rescue,''\emph{ICRA Singapore}, 2017 
%
\bibitem{Ouahouah2017}S. Ouahouah , T. Taleb, J. Song and C. Benzaid, ``Efficient offloading mechanism for UAVs-based value added services," \emph{IEEE International Conference on Communications (ICC)}, 2017
\bibitem{Valentino2018} R. Valentino, W.-S. Jung and Y.-B. Ko,``Opportunistic Computational Offloading System for Clusters of Drones,''\emph{International Conference on Advanced Communications Technology(ICACT)}, 2018 
%
\bibitem{Motlagh2017}N. H. Motlagh, M. Bagaa, and T. Taleb, ``Uav-based iot platform: A crowd surveillance use case,''\emph{IEEE Communications Magazine}, vol.55, no.2, pp. 128\UTF{2013}134, 2017
%
\bibitem{Messous2017} M.-A. Messous, A. Arfaoui, A. Alioua, S. -M. Senouci,``A Sequential Game Approach for Computation-Offloading in an UAV Network,''\emph{IEEE Global Communications Conference}, 2017 
\bibitem{bebop2} S. A. Parrot, ``PARROT BEBOP2 SO LIGHT YOU CAN TAKE IT ANYWHERE TO FILM IN FULL HD", \url{http://www.parrot.com/usa/products/bebop2/}, 2016
%
\bibitem{Ren2015} S. Ren, K. He, R. Girshick, J. Sun, ``Faster R-CNN: Towards
real-time object detection with region proposal networks,'' \emph{In Advances in neural information processing systems}, pp. 91\UTF{2013}99, 2015
\bibitem{Li2013} J. Li, Y. Fan, H. Chen, K. Xu, Y. Dai, F. Yin, Y. Ji,  ``Radio-over-fiber-based distributed antenna systems supporting IEEE 802.11 N/AC standards,'' \emph{Optical Communications and Networks (ICOCN), 2013 12th International Conference on. IEEE}, pp. 1\UTF{2013}4, 2013
\bibitem{NOMURA2001}K. Nomura, K. Yamori, E. Takahashi, T. Miyoshi, and Y. Tanaka, ``Waiting time versus utility to download images.," \emph{4th Asia Pacific-Symposium on Information and Telecommunication Technologies}, pp. 128\UTF{2013}132, 2001

\end{thebibliography}



\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Kosei Miyano} received his B.E. degree in Electrical
and Electronic Engineering from Kyoto University,
Kyoto, Japan, in 2017. He is currently a graduate student of Communications and
Computer Engineering, Graduate School of Informatics,
Kyoto University. His research interest
is adaptive operation for unmanned aerial vehicles.
\end{IEEEbiography}



\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Ryoichi Shinkuma} received the B.E., M.E., and
Ph.D. degrees in Communications Engineering
from Osaka University, Japan, in 2000, 2001, and
2003, respectively. In 2003, he joined the faculty
of Communications and Computer Engineering,
Graduate School of Informatics, Kyoto University,
Japan, where he is currently an Associate Professor. He was a Visiting Scholar at Wireless Information Network Laboratory (WINLAB), Rutgers,
the State University of New Jersey, USA, from
2008 Fall to 2009 Fall. His research interests include network design and
control criteria, particularly inspired by economic and social aspects. He
received the Young Researchers' Award from IEICE in 2006 and the Young
Scientist Award from Ericsson Japan in 2007, respectively. He also received
the TELECOM System Technology Award from the Telecommunications
Advancement Foundation in 2016. He has been the chairperson of the
Mobile Network and Applications (MoNA) Technical Committee of IEICE
Communications Society since June 2017. He is a member of IEEE.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Narayan B. Mandayam} (S'89-M'94-SM'99-F'09) received the B.Tech (Hons.) degree in 1989
from the Indian Institute of Technology, Kharagpur, and
the M.S. and Ph.D. degrees in 1991 and 1994 from Rice
University, all in electrical engineering. Since 1994 he has
been at Rutgers University where he is currently a Distinguished
Professor and Chair of the Electrical and Computer
Engineering department. He also serves as Associate Director
at WINLAB. He was a visiting faculty fellow in the Department
of Electrical Engineering, Princeton University, in
2002 and a visiting faculty at the Indian Institute of Science,
Bangalore, India in 2003. Using constructs from game theory,
communications and networking, his work has focused
on system modeling, information processing and resource
management for enabling cognitive wireless technologies to
support various applications. He has been working recently
on the use of prospect theory in understanding the psychophysics
of pricing for wireless data networks as well as
the smart grid. His recent interests also include privacy in
IoT, resilient smart cities as well as modeling and analysis of
trustworthy knowledge creation on the internet. Dr. Mandayam
is a co-recipient of the 2015 IEEE Communications
Society Advances in Communications Award for his seminal
work on power control and pricing, the 2014 IEEE Donald
G. Fink Award for his IEEE Proceedings paper titled
``Frontiers of Wireless and Mobile Communications''and
the 2009 Fred W. Ellersick Prize from the IEEE Communications
Society for his work on dynamic spectrum access
models and spectrum policy. He is also a recipient of the
Peter D. Cherasia Faculty Scholar Award from Rutgers University
(2010), the National Science Foundation CAREER
Award (1998) and the Institute Silver Medal from the Indian
Institute of Technology (1989). He is a coauthor of the
books: Principles of Cognitive Radio (Cambridge University
Press, 2012) and Wireless Networks: Multiuser Detection
in Cross-Layer Design (Springer, 2004). He has served
as an Editor for the journals IEEE Communication Letters
and IEEE Transactions on Wireless Communications. He
has also served as a guest editor of the IEEE JSAC Special
Issues on Adaptive, Spectrum Agile and Cognitive Radio
Networks (2007) and Game Theory in Communication Systems
(2008). He is a Fellow and Distinguished Lecturer of
the IEEE.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Takehiro Sato} received the B.E. and M.E. degrees from Keio
University, Japan, in 2010 and 2011, respectively. He is currently
working toward the Ph.D. degree at the Graduate School of Science
and Technology, Keio University, Japan. His research interests include
communication protocols and network architectures for the
next-generation optical network. From 2011 to 2012, he was a research
assistant in the Keio University Global COE Program,
``High-Level Global Cooperation for Leading Edge Platform on
Access Spaces,” by the Ministry of Education, Culture, Sports,
Science, and Technology, Japan. He is currently a research fellow
of the Japan Society for the Promotion of Science (since 2012). He is
a student member of the IEEE and the IEICE.
\end{IEEEbiography}


\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/sample.png}}]{Eiji Oki} (M'95\UTF{2013}SM'05\UTF{2013}F'13) received the B.E. and
M.E. degrees in instrumentation engineering and the
Ph.D. degree in electrical engineering from Keio
University, Yokohama, Japan, in 1991, 1993, and
1999, respectively. In 1993, he joined the Nippon
Telegraph and Telephone Corporation (NTT) Communication
Switching Laboratories, Tokyo, Japan,
where he was involved in researching network
design and control, traffic control methods, and highspeed
switching systems. From 2000 to 2001, he
was a Visiting Scholar with the Polytechnic Institute
of New York University, Brooklyn, NY, USA, where he was involved in
designing terabit switch/router systems. He was engaged in researching
and developing high-speed optical IP backbone networks with the NTT
Laboratories. He joined The University of Electro-Communications, Tokyo,
in 2008, where he is currently a Professor. He has been active in the
standardization of the path computation element and GMPLS in the IETF.
He has authored over ten IETF RFCs. He has authored/coauthored four
books, Broadband Packet Switching Technologies (Wiley, 2001), GMPLS
Technologies (CRC Press, 2005), Advanced Internet Protocols, Services, and
Applications (Wiley, 2012), and Linear Programming and Algorithms for
Communication Networks, (CRC Press, 2012). He is a Fellow of the IEICE.
He was a recipient of several prestigious awards, including the 1998 Switching
System Research Award and the 1999 Excellent Paper Award presented by
IEICE, the 2001 Asia-Pacific Outstanding Young Researcher Award presented
by IEEE Communications Society for his contributions to broadband network,
ATM, and optical IP technologies, the 2010 Telecom System Technology
Prize by the Telecommunications Advanced Foundation, the IEEE HPSR 2012
Outstanding Paper Award, the IEEE HPSR 2014 Best Paper Award Finalist,
the First Runner Up, and the 2015 IEICE Achievement Award.
\end{IEEEbiography}



\EOD


\end{document}


